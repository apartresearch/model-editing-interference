{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["DcZG9rm2IAiA","Z4iJEGh6b56v","GCCCoO0V7L7J"],"authorship_tag":"ABX9TyOnHmFz1b7vhKpkX3DvL2YV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1801c7cc6a4d487b9583ae8aaed4b2f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d28b4eda53bc4927a081de5fb97ad7d3","IPY_MODEL_426c7bb53f0243ea90e31bd433b4c2c7","IPY_MODEL_8826c39f2d4d4d37a350856c07688e6d"],"layout":"IPY_MODEL_e6727c3cd1d7450b9c7ffe152b12fe26"}},"d28b4eda53bc4927a081de5fb97ad7d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b3212af25884172b0fefcc0a4b15d6a","placeholder":"​","style":"IPY_MODEL_d3ea659a9d2c4a7aa66e0ddde7015428","value":"Downloading (…)lve/main/config.json: 100%"}},"426c7bb53f0243ea90e31bd433b4c2c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e44854bc23bf43b79c3ac7b0e9846b3a","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_462a41ae17434ad19ffe0f15221ee9f7","value":665}},"8826c39f2d4d4d37a350856c07688e6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0290c5fa0f11480d899089fff767ef67","placeholder":"​","style":"IPY_MODEL_114548e09f634c92922a0fa3a1b4344c","value":" 665/665 [00:00&lt;00:00, 58.1kB/s]"}},"e6727c3cd1d7450b9c7ffe152b12fe26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b3212af25884172b0fefcc0a4b15d6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3ea659a9d2c4a7aa66e0ddde7015428":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e44854bc23bf43b79c3ac7b0e9846b3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"462a41ae17434ad19ffe0f15221ee9f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0290c5fa0f11480d899089fff767ef67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"114548e09f634c92922a0fa3a1b4344c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a54d045c846349fc9b405597d7f9f5a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7f8a1683ed8468ab7cb01233641d8a6","IPY_MODEL_7e770fc3c21448fea8c7dc3d5950b9dd","IPY_MODEL_28a9d31c9e764218830307a37e358b99"],"layout":"IPY_MODEL_8945f4af835d4c3eb974187a635f3005"}},"e7f8a1683ed8468ab7cb01233641d8a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a70b9c3d9db746afbcbcfa2401d03813","placeholder":"​","style":"IPY_MODEL_92198a210bb24b0a9e134ee1fe354f3b","value":"Downloading model.safetensors: 100%"}},"7e770fc3c21448fea8c7dc3d5950b9dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96f8e886177e4e0e8fa726a10b1bde02","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec5bfc8381f548699475aaa2d93ae894","value":548105171}},"28a9d31c9e764218830307a37e358b99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4bfb308e0414a7eb61c22ffd6a4664f","placeholder":"​","style":"IPY_MODEL_37a23b5490ee4a86b82da051025a0536","value":" 548M/548M [00:01&lt;00:00, 461MB/s]"}},"8945f4af835d4c3eb974187a635f3005":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a70b9c3d9db746afbcbcfa2401d03813":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92198a210bb24b0a9e134ee1fe354f3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96f8e886177e4e0e8fa726a10b1bde02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec5bfc8381f548699475aaa2d93ae894":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4bfb308e0414a7eb61c22ffd6a4664f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37a23b5490ee4a86b82da051025a0536":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bd62c721bf84bd98b806735addbed31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ac7986cab9c457ebf0194375198a1ac","IPY_MODEL_0d1bf4ba26e4482f941fe75c480240ac","IPY_MODEL_244af246622d44c2b0d1358218971bfb"],"layout":"IPY_MODEL_62bcdcc5e5e24a569e74db5cb57ac834"}},"9ac7986cab9c457ebf0194375198a1ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7889fa63ddc43ae94390b8b909102b7","placeholder":"​","style":"IPY_MODEL_9a1d91da52b1420dbfd61212bba76a4b","value":"Downloading (…)neration_config.json: 100%"}},"0d1bf4ba26e4482f941fe75c480240ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8ce3e300b9a452eb9fdd63ac48e4f28","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9545de5f9f0b4dc898e58e5422d01c5b","value":124}},"244af246622d44c2b0d1358218971bfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5a2f8458f3a4318be4210ccf1baa343","placeholder":"​","style":"IPY_MODEL_a24c754174124981ae5f5bcc5a0f4892","value":" 124/124 [00:00&lt;00:00, 11.6kB/s]"}},"62bcdcc5e5e24a569e74db5cb57ac834":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7889fa63ddc43ae94390b8b909102b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a1d91da52b1420dbfd61212bba76a4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8ce3e300b9a452eb9fdd63ac48e4f28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9545de5f9f0b4dc898e58e5422d01c5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5a2f8458f3a4318be4210ccf1baa343":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a24c754174124981ae5f5bcc5a0f4892":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7c10929e5d14865a6a8558814c288b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6af870eb3ac24a299f9691b1b7b55429","IPY_MODEL_7f23056ccc79400789a91841479e14ef","IPY_MODEL_49429893679f4db5864b48201dc20383"],"layout":"IPY_MODEL_ec4b3232f9804607bf922fe52ecd4f69"}},"6af870eb3ac24a299f9691b1b7b55429":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1da3907d8704361a4217ad2c02fc38a","placeholder":"​","style":"IPY_MODEL_172ddbc396644c55b95378d33171f156","value":"Downloading (…)olve/main/vocab.json: 100%"}},"7f23056ccc79400789a91841479e14ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b8b17e8adef48c5880b6e269786a133","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79be7254788f41adb0d06b9229f7e3b5","value":1042301}},"49429893679f4db5864b48201dc20383":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4084149ae354450abdcd91985015d5c","placeholder":"​","style":"IPY_MODEL_cc5de7a52fcc4c829958ef459695d409","value":" 1.04M/1.04M [00:00&lt;00:00, 3.14MB/s]"}},"ec4b3232f9804607bf922fe52ecd4f69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1da3907d8704361a4217ad2c02fc38a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"172ddbc396644c55b95378d33171f156":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b8b17e8adef48c5880b6e269786a133":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79be7254788f41adb0d06b9229f7e3b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4084149ae354450abdcd91985015d5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc5de7a52fcc4c829958ef459695d409":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e9464cdf61f460eb2b4d02d69554028":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41b9b3c0510746f59996d283c115dbbc","IPY_MODEL_ad1e143bdaac42eda0790b6a9b63a76d","IPY_MODEL_f35ccd4f12ef495d90ad354948e74cac"],"layout":"IPY_MODEL_c73433bf4b3c4c3394228fc91691d7bf"}},"41b9b3c0510746f59996d283c115dbbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbf9bad5ec1748d48569ba2f0451ecb1","placeholder":"​","style":"IPY_MODEL_3fb583750dfe415b92cd9932bedac41b","value":"Downloading (…)olve/main/merges.txt: 100%"}},"ad1e143bdaac42eda0790b6a9b63a76d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc83b2239078443ba67107cb160f8c7b","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0f6b1c3c2d448ff9e2b94f98132851d","value":456318}},"f35ccd4f12ef495d90ad354948e74cac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_293217e3c0504acbaf4987d88665189d","placeholder":"​","style":"IPY_MODEL_3fead53a9e6d466db4d22c5f8b14c1a2","value":" 456k/456k [00:00&lt;00:00, 1.83MB/s]"}},"c73433bf4b3c4c3394228fc91691d7bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbf9bad5ec1748d48569ba2f0451ecb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fb583750dfe415b92cd9932bedac41b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc83b2239078443ba67107cb160f8c7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0f6b1c3c2d448ff9e2b94f98132851d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"293217e3c0504acbaf4987d88665189d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fead53a9e6d466db4d22c5f8b14c1a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f103a21701243fc9b54b3b357d975fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb1f14a711bd463bbda763c6376c89b7","IPY_MODEL_8f4562aeb13d4a1f9ac0f5308b5e94a8","IPY_MODEL_404252b087a64811b89480e8df3ce4a3"],"layout":"IPY_MODEL_093a4f55ad284344bb375fd915775519"}},"cb1f14a711bd463bbda763c6376c89b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfde810727834d35b02c5ad94bfabc09","placeholder":"​","style":"IPY_MODEL_5936ff89e9be461390210906b3cf955d","value":"Downloading (…)/main/tokenizer.json: 100%"}},"8f4562aeb13d4a1f9ac0f5308b5e94a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef18673cc5b742628e346259efdb5fae","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b346db0647f41bd9690475a44389370","value":1355256}},"404252b087a64811b89480e8df3ce4a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5962c48068ba46fdabbe52c29b0a0db7","placeholder":"​","style":"IPY_MODEL_f927eecc56074a3b9c6be7d4be0a2c54","value":" 1.36M/1.36M [00:00&lt;00:00, 15.6MB/s]"}},"093a4f55ad284344bb375fd915775519":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfde810727834d35b02c5ad94bfabc09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5936ff89e9be461390210906b3cf955d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef18673cc5b742628e346259efdb5fae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b346db0647f41bd9690475a44389370":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5962c48068ba46fdabbe52c29b0a0db7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f927eecc56074a3b9c6be7d4be0a2c54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"b13177b7"},"source":["<a href=\"https://colab.research.google.com/github/wlg100/numseqcont_circuit_expms/blob/main/notebook_templates/minimal_circuit_template.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."]},{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup\n","(No need to change anything)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rMcpSDdjIAiA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696821203685,"user_tz":240,"elapsed":103244,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1a8a2e1d-f9b8-49c6-dac5-ef63f74b10e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running as a Colab notebook\n","Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n","  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-6wfzqhsa\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-6wfzqhsa\n","  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 3f929b1d142b8f82bfbb8ae30e69bab7f76cadf3\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n","  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n","  Downloading jaxtyping-0.2.22-py3-none-any.whl (25 kB)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.23.5)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.6.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.0.1+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n","Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n","  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n","  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n","Collecting xxhash (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.5)\n","Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (6.0.1)\n","Collecting typeguard>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n","  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (17.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n","Collecting tokenizers<0.15,>=0.14 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n","Collecting typing-extensions>=3.7.4.1 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: transformer-lens, pathtools\n","  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=110263 sha256=cfa6869f3fb3e62468cf9cf226f256332a87173654617b5bc7dc2fbed787dadd\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dwp2cdpi/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=83c74c70468ec2212ed845c9fbb17bc36abaca6da73e0a43e62b9e809e2fc61e\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built transformer-lens pathtools\n","Installing collected packages: pathtools, xxhash, typing-extensions, smmap, setproctitle, sentry-sdk, safetensors, fancy-einsum, einops, docker-pycreds, dill, beartype, typeguard, multiprocess, huggingface-hub, gitdb, tokenizers, jaxtyping, GitPython, wandb, transformers, datasets, transformer-lens\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed GitPython-3.1.37 beartype-0.14.1 datasets-2.14.5 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.10 huggingface-hub-0.17.3 jaxtyping-0.2.22 multiprocess-0.70.15 pathtools-0.1.2 safetensors-0.4.0 sentry-sdk-1.31.0 setproctitle-1.3.3 smmap-5.0.1 tokenizers-0.14.1 transformer-lens-0.0.0 transformers-4.34.0 typeguard-4.1.5 typing-extensions-4.8.0 wandb-0.15.12 xxhash-3.4.1\n","\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","  \u001b[1m\u001b[33m                         \u001b[4mSCRIPT DEPRECATION WARNING\u001b[m                    \u001b[m\n","\n","  \n","  This script, located at \u001b[1mhttps://deb.nodesource.com/setup_X\u001b[m, used to\n","  install Node.js is deprecated now and will eventually be made inactive.\n","\n","  Please visit the NodeSource \u001b[1mdistributions\u001b[m Github and follow the\n","  instructions to migrate your repo.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","  The \u001b[1mNodeSource\u001b[m Node.js Linux distributions GitHub repository contains\n","  information about which versions of Node.js and which Linux distributions\n","  are supported and how to install it.\n","  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n","\n","\n","                          \u001b[4m\u001b[1m\u001b[33mSCRIPT DEPRECATION WARNING\u001b[m\n","\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n","\u001b[1m\u001b[31m================================================================================\u001b[m\n","\n","\u001b[36m\u001b[1mTO AVOID THIS WAIT MIGRATE THE SCRIPT\u001b[m\n","Continuing in 60 seconds (press Ctrl-C to abort) ...\n","\n","\n","## Installing the NodeSource Node.js 16.x repo...\n","\n","\n","## Populating apt-get cache...\n","\n","+ apt-get update\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,266 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,342 kB]\n","Fetched 2,950 kB in 1s (2,109 kB/s)\n","Reading package lists... Done\n","\n","## Confirming \"jammy\" is supported...\n","\n","+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n","\n","## Adding the NodeSource signing key to your keyring...\n","\n","+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n","\n","## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n","\n","+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n","+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n","\n","## Running `apt-get update` for you...\n","\n","+ apt-get update\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:2 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:4 https://deb.nodesource.com/node_16.x jammy InRelease [4,583 B]\n","Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Hit:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Get:11 https://deb.nodesource.com/node_16.x jammy/main amd64 Packages [776 B]\n","Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Fetched 5,359 B in 1s (6,499 B/s)\n","Reading package lists... Done\n","\n","## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n","## You may also need development tools to build native addons:\n","     sudo apt-get install gcc g++ make\n","## To install the Yarn package manager, run:\n","     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n","     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n","     sudo apt-get update && sudo apt-get install yarn\n","\n","\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  nodejs\n","0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n","Need to get 27.2 MB of archives.\n","After this operation, 128 MB of additional disk space will be used.\n","Get:1 https://deb.nodesource.com/node_16.x jammy/main amd64 nodejs amd64 16.20.2-deb-1nodesource1 [27.2 MB]\n","Fetched 27.2 MB in 0s (62.4 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package nodejs.\n","(Reading database ... 120875 files and directories currently installed.)\n","Preparing to unpack .../nodejs_16.20.2-deb-1nodesource1_amd64.deb ...\n","Unpacking nodejs (16.20.2-deb-1nodesource1) ...\n","Setting up nodejs (16.20.2-deb-1nodesource1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Collecting git+https://github.com/neelnanda-io/PySvelte.git\n","  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-lr1p4n7c\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-lr1p4n7c\n","  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n"]}],"source":["# Janky code to do different setup when run in a Colab notebook vs VSCode\n","DEBUG_MODE = False\n","try:\n","    import google.colab\n","    IN_COLAB = True\n","    print(\"Running as a Colab notebook\")\n","    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n","    # Install another version of node that makes PySvelte work way faster\n","    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n","    %pip install git+https://github.com/neelnanda-io/PySvelte.git\n","except:\n","    IN_COLAB = False\n","    print(\"Running as a Jupyter notebook - intended for development only!\")\n","    from IPython import get_ipython\n","\n","    ipython = get_ipython()\n","    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n","    ipython.magic(\"load_ext autoreload\")\n","    ipython.magic(\"autoreload 2\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xKoTs7VBIAiD","executionInfo":{"status":"ok","timestamp":1696821203685,"user_tz":240,"elapsed":19,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n","import plotly.io as pio\n","\n","if IN_COLAB or not DEBUG_MODE:\n","    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n","    pio.renderers.default = \"colab\"\n","else:\n","    pio.renderers.default = \"png\""]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1696821210420,"user_tz":240,"elapsed":6752,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1696821210662,"user_tz":240,"elapsed":249,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["# import pysvelte\n","\n","import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cFMTUcQiIAiF","outputId":"d7bddf17-d13d-4636-85ad-4983e78dc0d6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696821210663,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7e2757f59d80>"]},"metadata":{},"execution_count":5}],"source":["torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"zyKb4C51IAiG"},"source":["Plotting helper functions:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"KFs9BrbzIAiH","executionInfo":{"status":"ok","timestamp":1696821210663,"user_tz":240,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def imshow(tensor, renderer=None, **kwargs):\n","    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n","\n","def line(tensor, renderer=None, **kwargs):\n","    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n","\n","def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n","    x = utils.to_numpy(x)\n","    y = utils.to_numpy(y)\n","    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"markdown","source":["Decide which model to use (eg. gpt2-small vs -medium)"],"metadata":{"id":"ssJgoKr2yI8O"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"xLwDyosvIAiJ","executionInfo":{"status":"ok","timestamp":1696821226504,"user_tz":240,"elapsed":15846,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["1801c7cc6a4d487b9583ae8aaed4b2f0","d28b4eda53bc4927a081de5fb97ad7d3","426c7bb53f0243ea90e31bd433b4c2c7","8826c39f2d4d4d37a350856c07688e6d","e6727c3cd1d7450b9c7ffe152b12fe26","8b3212af25884172b0fefcc0a4b15d6a","d3ea659a9d2c4a7aa66e0ddde7015428","e44854bc23bf43b79c3ac7b0e9846b3a","462a41ae17434ad19ffe0f15221ee9f7","0290c5fa0f11480d899089fff767ef67","114548e09f634c92922a0fa3a1b4344c","a54d045c846349fc9b405597d7f9f5a6","e7f8a1683ed8468ab7cb01233641d8a6","7e770fc3c21448fea8c7dc3d5950b9dd","28a9d31c9e764218830307a37e358b99","8945f4af835d4c3eb974187a635f3005","a70b9c3d9db746afbcbcfa2401d03813","92198a210bb24b0a9e134ee1fe354f3b","96f8e886177e4e0e8fa726a10b1bde02","ec5bfc8381f548699475aaa2d93ae894","f4bfb308e0414a7eb61c22ffd6a4664f","37a23b5490ee4a86b82da051025a0536","6bd62c721bf84bd98b806735addbed31","9ac7986cab9c457ebf0194375198a1ac","0d1bf4ba26e4482f941fe75c480240ac","244af246622d44c2b0d1358218971bfb","62bcdcc5e5e24a569e74db5cb57ac834","c7889fa63ddc43ae94390b8b909102b7","9a1d91da52b1420dbfd61212bba76a4b","a8ce3e300b9a452eb9fdd63ac48e4f28","9545de5f9f0b4dc898e58e5422d01c5b","c5a2f8458f3a4318be4210ccf1baa343","a24c754174124981ae5f5bcc5a0f4892","f7c10929e5d14865a6a8558814c288b6","6af870eb3ac24a299f9691b1b7b55429","7f23056ccc79400789a91841479e14ef","49429893679f4db5864b48201dc20383","ec4b3232f9804607bf922fe52ecd4f69","d1da3907d8704361a4217ad2c02fc38a","172ddbc396644c55b95378d33171f156","5b8b17e8adef48c5880b6e269786a133","79be7254788f41adb0d06b9229f7e3b5","c4084149ae354450abdcd91985015d5c","cc5de7a52fcc4c829958ef459695d409","9e9464cdf61f460eb2b4d02d69554028","41b9b3c0510746f59996d283c115dbbc","ad1e143bdaac42eda0790b6a9b63a76d","f35ccd4f12ef495d90ad354948e74cac","c73433bf4b3c4c3394228fc91691d7bf","fbf9bad5ec1748d48569ba2f0451ecb1","3fb583750dfe415b92cd9932bedac41b","bc83b2239078443ba67107cb160f8c7b","e0f6b1c3c2d448ff9e2b94f98132851d","293217e3c0504acbaf4987d88665189d","3fead53a9e6d466db4d22c5f8b14c1a2","3f103a21701243fc9b54b3b357d975fc","cb1f14a711bd463bbda763c6376c89b7","8f4562aeb13d4a1f9ac0f5308b5e94a8","404252b087a64811b89480e8df3ce4a3","093a4f55ad284344bb375fd915775519","dfde810727834d35b02c5ad94bfabc09","5936ff89e9be461390210906b3cf955d","ef18673cc5b742628e346259efdb5fae","0b346db0647f41bd9690475a44389370","5962c48068ba46fdabbe52c29b0a0db7","f927eecc56074a3b9c6be7d4be0a2c54"],"height":0},"outputId":"f799c6a8-3932-462a-f357-52e94a1bf3e6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1801c7cc6a4d487b9583ae8aaed4b2f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54d045c846349fc9b405597d7f9f5a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bd62c721bf84bd98b806735addbed31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c10929e5d14865a6a8558814c288b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e9464cdf61f460eb2b4d02d69554028"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f103a21701243fc9b54b3b357d975fc"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using pad_token, but it is not set yet.\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    \"gpt2-small\",\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/callummcdougall/ARENA_2.0.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fdh5--MfYw7-","executionInfo":{"status":"ok","timestamp":1696821236354,"user_tz":240,"elapsed":9889,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"714920ae-d914-446e-cc07-9efec1ea7a41"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ARENA_2.0'...\n","remote: Enumerating objects: 9063, done.\u001b[K\n","remote: Counting objects: 100% (9063/9063), done.\u001b[K\n","remote: Compressing objects: 100% (3540/3540), done.\u001b[K\n","remote: Total 9063 (delta 5508), reused 8890 (delta 5425), pack-reused 0\u001b[K\n","Receiving objects: 100% (9063/9063), 155.49 MiB | 30.30 MiB/s, done.\n","Resolving deltas: 100% (5508/5508), done.\n"]}]},{"cell_type":"code","source":["cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZ4C_bsXZFfj","executionInfo":{"status":"ok","timestamp":1696821236355,"user_tz":240,"elapsed":32,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"05c69808-8c55-4c80-a8ec-16c8d4387cd0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"]}]},{"cell_type":"code","source":["import ioi_circuit_extraction as ioi_circuit_extraction"],"metadata":{"id":"OT0Sn571ZnkV","executionInfo":{"status":"ok","timestamp":1696821236355,"user_tz":240,"elapsed":31,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Generate dataset with multiple prompts"],"metadata":{"id":"cGX9iHAz_UKX"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, tokenizer, S1_is_first=False):\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.io_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"S5\"])[0] for prompt in self.prompts\n","        ]\n","        self.s_tokenIDs = [\n","            self.tokenizer.encode(\" \" + prompt[\"S4\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'S5')]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = model.tokenizer.tokenize(input_text)\n","                if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                    target_token = prompt[targ]\n","                else:\n","                    target_token = \"Ġ\" + prompt[targ]\n","                target_index = tokens.index(target_token)\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"4wXBNWj5FwVn","executionInfo":{"status":"ok","timestamp":1696821236355,"user_tz":240,"elapsed":30,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Repalce io_tokens with correct answer (next, which is '5') and s_tokens with incorrect (current, which repeats)"],"metadata":{"id":"exuTCQ_XmmFP"}},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': str(i),\n","            'S2': str(i+1),\n","            'S3': str(i+2),\n","            'S4': str(i+3),\n","            'S5': str(i+4),\n","            'text': f\"{i} {i+1} {i+2} {i+3}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 11)\n","dataset = Dataset(prompts_list, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"u0NPSKcZ1iDe","executionInfo":{"status":"ok","timestamp":1696821236355,"user_tz":240,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_corr(x ,y):\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': str(i),\n","            'S2': str(i),\n","            'S3': str(i),\n","            'S4': str(i),\n","            'S5': str(i),\n","            'text': f\"{i} {i} {i} {i}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list_2 = generate_prompts_list_corr(1, 11)\n","dataset_2 = Dataset(prompts_list_2, model.tokenizer, S1_is_first=True)"],"metadata":{"id":"dzzLlCqZS_wl","executionInfo":{"status":"ok","timestamp":1696821565800,"user_tz":240,"elapsed":567,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["Logit diff is correct - incorr token. Here, correct is S5, and incorr is S4.\n","\n","Because of this, it's possible to have logit diffs HIGHER than the \"full circuit\" because the correct token will still be at first place, but the logit scores assigned will just be bigger (perhaps incorrect is scored even lower in the non-full circuit with a higher logit diff score)?"],"metadata":{"id":"A0W-GaM6Vfm-"}},{"cell_type":"markdown","source":["# Ablation Expm Functions"],"metadata":{"id":"GCCCoO0V7L7J"}},{"cell_type":"code","source":["from torch import Tensor\n","\n","def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n","    '''\n","    Returns logit difference between the correct and incorrect answer.\n","\n","    If per_prompt=True, return the array of differences rather than the average.\n","    '''\n","\n","    # Only the final logits are relevant for the answer\n","    # Get the logits corresponding to the indirect object / subject tokens respectively\n","    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n","    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n","    # Find logit difference\n","    answer_logit_diff = io_logits - s_logits\n","    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"],"metadata":{"id":"CgD41x5nbKKP","executionInfo":{"status":"ok","timestamp":1696821236356,"user_tz":240,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def mean_ablate_by_lst(lst, model, print_output=True):\n","    CIRCUIT = {\n","        \"number mover\": lst,\n","        \"number mover 4\": lst,\n","        \"number mover 3\": lst,\n","        \"number mover 2\": lst,\n","        \"number mover 1\": lst,\n","    }\n","\n","    SEQ_POS_TO_KEEP = {\n","        \"number mover\": \"end\",\n","        \"number mover 4\": \"S4\",\n","        \"number mover 3\": \"S3\",\n","        \"number mover 2\": \"S2\",\n","        \"number mover 1\": \"S1\",\n","    }\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n","\n","    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n","    ioi_logits_minimal = model(dataset.toks)\n","\n","    orig_score = logits_to_ave_logit_diff_2(ioi_logits_original, dataset)\n","    new_score = logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset)\n","    if print_output:\n","        # print(f\"Average logit difference (IOI dataset, using entire model): {orig_score:.4f}\")\n","        # print(f\"Average logit difference (IOI dataset, only using circuit): {new_score:.4f}\")\n","        print(f\"Average logit difference (circuit / full) %: {100 * new_score / orig_score:.4f}\")\n","    # return new_score\n","    return 100 * new_score / orig_score"],"metadata":{"id":"LqsdFmbVMntG","executionInfo":{"status":"ok","timestamp":1696821236356,"user_tz":240,"elapsed":29,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["We can also prevent redundant computation of the full circuit score by storing it and just passing it in to the function."],"metadata":{"id":"xUlhxzuGUr1y"}},{"cell_type":"markdown","source":["# Ablate the model and compare with original"],"metadata":{"id":"Lk3bffnCYq-p"}},{"cell_type":"markdown","source":["### try full circuit from repeatLast iter fb"],"metadata":{"id":"x2IM79qgcx4F"}},{"cell_type":"code","source":["curr_circuit = [(0, 1), (0, 3), (0, 5), (0, 7), (0, 8), (0, 9), (0, 10), (1, 0), (1, 5), (3, 0), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 8), (4, 10), (4, 11), (5, 4), (5, 5), (5, 9), (6, 1), (6, 6), (6, 10), (7, 6), (7, 10), (7, 11), (8, 1), (8, 2), (8, 6), (8, 8), (9, 1), (9, 5), (10, 7), (11, 10)]\n","mean_ablate_by_lst(curr_circuit, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESPP2WGsc0E2","executionInfo":{"status":"ok","timestamp":1696821649336,"user_tz":240,"elapsed":3095,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"938eb81a-2e9e-42f1-9e44-d287e0e803ed"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 49.2276\n"]},{"output_type":"execute_result","data":{"text/plain":["49.22761154174805"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["curr_circuit = [(0, 1)]\n","mean_ablate_by_lst(curr_circuit, model, print_output=True).item()"],"metadata":{"id":"iWDb4eskc7WF","executionInfo":{"status":"ok","timestamp":1696821668302,"user_tz":240,"elapsed":2868,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"d1e9dd1f-9b50-438f-97fb-ecbf729223c3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: -6.5109\n"]},{"output_type":"execute_result","data":{"text/plain":["-6.510853290557861"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## Work backwards\n","\n","https://www.notion.so/wlg1/Search-Methods-brainstorm-15a3020ab00b40adb79b0acf3622f5f4?pvs=4#dd6b43247d4945eda1d70ca4d4bae01d"],"metadata":{"id":"e6N5MU1wRZog"}},{"cell_type":"code","source":["# Start with full circuit\n","curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","threshold = 3  # This is T, a %. if performance is less than T%, allow its removal\n","\n","for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","    for head in range(12):\n","        # Copying the curr_circuit so we can iterate over one and modify the other\n","        copy_circuit = curr_circuit.copy()\n","\n","        # Temporarily removing the current tuple from the copied circuit\n","        copy_circuit.remove((layer, head))\n","\n","        new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","        # print((layer,head), new_score)\n","        # If the result is less than the threshold, remove the tuple from the original list\n","        if (100 - new_score) < threshold:\n","            curr_circuit.remove((layer, head))\n","\n","            print(\"Removed:\", (layer, head))\n","            print(new_score)\n","            print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"Bfiwe5d3SgVP","executionInfo":{"status":"error","timestamp":1696821539695,"user_tz":240,"elapsed":303368,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4ccc130d-0acf-44c1-9bf0-a066e475b544"},"execution_count":16,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-ef502314e549>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcopy_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mnew_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_ablate_by_lst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# print((layer,head), new_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-c26448ca9fee>\u001b[0m in \u001b[0;36mmean_ablate_by_lst\u001b[0;34m(lst, model, print_output)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mioi_logits_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioi_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_with_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mioi_circuit_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_mean_ablation_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCIRCUIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_pos_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_POS_TO_KEEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mioi_logits_minimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py\u001b[0m in \u001b[0;36madd_mean_ablation_hook\u001b[0;34m(model, means_dataset, circuit, seq_pos_to_keep, is_permanent)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Apply hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"z\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_permanent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_permanent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36madd_hook\u001b[0;34m(self, name, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook_point_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_point_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                     self.check_and_add_hook(\n\u001b[0m\u001b[1;32m    251\u001b[0m                         \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                         \u001b[0mhook_point_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36mcheck_and_add_hook\u001b[0;34m(self, hook_point, hook_point_name, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mprepend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         )\n\u001b[0;32m--> 223\u001b[0;31m         hook_point.add_hook(\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_permanent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_permanent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py\u001b[0m in \u001b[0;36madd_hook\u001b[0;34m(self, hook, dir, is_permanent, level, prepend)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             full_hook.__name__ = (\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             )  # annotate the `full_hook` with the string representation of the `hook` function\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    424\u001b[0m             )\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     def backward(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disable_current_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0mguard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DisableFuncTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_contents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    565\u001b[0m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m                         \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         slices = (\n\u001b[0;32m--> 261\u001b[0;31m             [\n\u001b[0m\u001b[1;32m    262\u001b[0m                 _tensor_str_with_formatter(\n\u001b[1;32m    263\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         slices = (\n\u001b[1;32m    261\u001b[0m             [\n\u001b[0;32m--> 262\u001b[0;31m                 _tensor_str_with_formatter(\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         slices = (\n\u001b[0;32m--> 261\u001b[0;31m             [\n\u001b[0m\u001b[1;32m    262\u001b[0m                 _tensor_str_with_formatter(\n\u001b[1;32m    263\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         slices = (\n\u001b[1;32m    261\u001b[0m             [\n\u001b[0;32m--> 262\u001b[0;31m                 _tensor_str_with_formatter(\n\u001b[0m\u001b[1;32m    263\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    274\u001b[0m         )\n\u001b[1;32m    275\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         slices = [\n\u001b[0m\u001b[1;32m    277\u001b[0m             _tensor_str_with_formatter(\n\u001b[1;32m    278\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         slices = [\n\u001b[0;32m--> 277\u001b[0;31m             _tensor_str_with_formatter(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    266\u001b[0m             ]\n\u001b[1;32m    267\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"...\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             + [\n\u001b[0m\u001b[1;32m    269\u001b[0m                 _tensor_str_with_formatter(\n\u001b[1;32m    270\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"...\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             + [\n\u001b[0;32m--> 269\u001b[0;31m                 _tensor_str_with_formatter(\n\u001b[0m\u001b[1;32m    270\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vector_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_vector_str\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0m_val_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" ...\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_val_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["mean_ablate_by_lst(curr_circuit, model, print_output=True).item()"],"metadata":{"id":"qgpGMTWLbibq","executionInfo":{"status":"aborted","timestamp":1696821539697,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_circuit"],"metadata":{"id":"7_ZC4-k2blg2","executionInfo":{"status":"aborted","timestamp":1696821539697,"user_tz":240,"elapsed":10,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now try 10% threshold:"],"metadata":{"id":"7vMvM9iRiPyo"}},{"cell_type":"code","source":["def find_circuit_backw(threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    # Start with full circuit\n","    curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"Removed:\", (layer, head))\n","                print(new_score)\n","                print(\"\\n\")\n","\n","    return curr_circuit"],"metadata":{"id":"JL6UvAikiQFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_circuit = find_circuit_backw(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1IIpte21ipBz","executionInfo":{"status":"ok","timestamp":1696454560023,"user_tz":240,"elapsed":340874,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"524b0576-aff6-4946-fc3d-83cc92f81275"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (11, 0)\n","99.02855682373047\n","\n","\n","Removed: (11, 1)\n","99.0681381225586\n","\n","\n","Removed: (11, 2)\n","99.27287292480469\n","\n","\n","Removed: (11, 3)\n","99.61582946777344\n","\n","\n","Removed: (11, 4)\n","100.09127807617188\n","\n","\n","Removed: (11, 5)\n","100.09712982177734\n","\n","\n","Removed: (11, 6)\n","100.05851745605469\n","\n","\n","Removed: (11, 7)\n","99.9634017944336\n","\n","\n","Removed: (11, 8)\n","99.3410873413086\n","\n","\n","Removed: (11, 9)\n","99.123291015625\n","\n","\n","Removed: (11, 10)\n","98.09922790527344\n","\n","\n","Removed: (11, 11)\n","99.79859161376953\n","\n","\n","Removed: (10, 0)\n","99.7418212890625\n","\n","\n","Removed: (10, 1)\n","98.1563491821289\n","\n","\n","Removed: (10, 2)\n","100.61833953857422\n","\n","\n","Removed: (10, 3)\n","100.79714965820312\n","\n","\n","Removed: (10, 4)\n","100.48069763183594\n","\n","\n","Removed: (10, 5)\n","100.26615142822266\n","\n","\n","Removed: (10, 6)\n","100.29136657714844\n","\n","\n","Removed: (10, 8)\n","100.43941497802734\n","\n","\n","Removed: (10, 9)\n","100.6727294921875\n","\n","\n","Removed: (10, 10)\n","101.22868347167969\n","\n","\n","Removed: (10, 11)\n","100.94214630126953\n","\n","\n","Removed: (9, 0)\n","100.90746307373047\n","\n","\n","Removed: (9, 2)\n","100.99788665771484\n","\n","\n","Removed: (9, 3)\n","102.2463150024414\n","\n","\n","Removed: (9, 4)\n","101.65393829345703\n","\n","\n","Removed: (9, 5)\n","99.0406265258789\n","\n","\n","Removed: (9, 6)\n","98.59606170654297\n","\n","\n","Removed: (9, 7)\n","98.39341735839844\n","\n","\n","Removed: (9, 8)\n","98.37744140625\n","\n","\n","Removed: (9, 9)\n","99.22708892822266\n","\n","\n","Removed: (9, 10)\n","99.09109497070312\n","\n","\n","Removed: (9, 11)\n","98.2387924194336\n","\n","\n","Removed: (8, 0)\n","96.51646423339844\n","\n","\n","Removed: (8, 1)\n","95.41947937011719\n","\n","\n","Removed: (8, 2)\n","95.38134765625\n","\n","\n","Removed: (8, 3)\n","96.60670471191406\n","\n","\n","Removed: (8, 4)\n","96.59247589111328\n","\n","\n","Removed: (8, 5)\n","95.3084716796875\n","\n","\n","Removed: (8, 6)\n","90.39507293701172\n","\n","\n","Removed: (8, 7)\n","90.92627716064453\n","\n","\n","Removed: (8, 9)\n","91.3223876953125\n","\n","\n","Removed: (8, 10)\n","90.71563720703125\n","\n","\n","Removed: (8, 11)\n","91.69187927246094\n","\n","\n","Removed: (7, 0)\n","90.26416778564453\n","\n","\n","Removed: (7, 1)\n","90.07434844970703\n","\n","\n","Removed: (7, 3)\n","91.90091705322266\n","\n","\n","Removed: (7, 4)\n","91.95289611816406\n","\n","\n","Removed: (7, 5)\n","90.92469787597656\n","\n","\n","Removed: (7, 7)\n","90.30686950683594\n","\n","\n","Removed: (7, 8)\n","90.49059295654297\n","\n","\n","Removed: (7, 9)\n","90.00527954101562\n","\n","\n","Removed: (6, 0)\n","90.41345977783203\n","\n","\n","Removed: (6, 2)\n","90.28367614746094\n","\n","\n","Removed: (6, 5)\n","91.8583984375\n","\n","\n","Removed: (6, 7)\n","91.76748657226562\n","\n","\n","Removed: (6, 8)\n","90.04991912841797\n","\n","\n","Removed: (6, 9)\n","91.46195220947266\n","\n","\n","Removed: (6, 11)\n","90.95195007324219\n","\n","\n","Removed: (5, 0)\n","90.3540267944336\n","\n","\n","Removed: (5, 2)\n","90.6308822631836\n","\n","\n","Removed: (5, 3)\n","90.04108428955078\n","\n","\n","Removed: (5, 7)\n","90.08610534667969\n","\n","\n","Removed: (5, 11)\n","90.75971221923828\n","\n","\n","Removed: (4, 0)\n","90.80105590820312\n","\n","\n","Removed: (4, 1)\n","91.10873413085938\n","\n","\n","Removed: (4, 2)\n","91.04916381835938\n","\n","\n","Removed: (4, 3)\n","91.2154312133789\n","\n","\n","Removed: (4, 5)\n","91.24647521972656\n","\n","\n","Removed: (4, 6)\n","90.27848815917969\n","\n","\n","Removed: (4, 9)\n","90.33191680908203\n","\n","\n","Removed: (4, 11)\n","91.1695327758789\n","\n","\n","Removed: (3, 1)\n","91.27881622314453\n","\n","\n","Removed: (3, 2)\n","90.30309295654297\n","\n","\n","Removed: (3, 4)\n","91.80142211914062\n","\n","\n","Removed: (3, 5)\n","91.73086547851562\n","\n","\n","Removed: (3, 6)\n","90.68115234375\n","\n","\n","Removed: (3, 8)\n","90.38886260986328\n","\n","\n","Removed: (3, 9)\n","90.35133361816406\n","\n","\n","Removed: (3, 10)\n","91.04875946044922\n","\n","\n","Removed: (3, 11)\n","91.02650451660156\n","\n","\n","Removed: (2, 0)\n","91.34190368652344\n","\n","\n","Removed: (2, 1)\n","92.22430419921875\n","\n","\n","Removed: (2, 3)\n","92.0880355834961\n","\n","\n","Removed: (2, 4)\n","91.62516021728516\n","\n","\n","Removed: (2, 5)\n","91.62088775634766\n","\n","\n","Removed: (2, 6)\n","91.58737182617188\n","\n","\n","Removed: (2, 7)\n","91.2184829711914\n","\n","\n","Removed: (2, 8)\n","90.83534240722656\n","\n","\n","Removed: (2, 10)\n","90.93058776855469\n","\n","\n","Removed: (2, 11)\n","91.3025131225586\n","\n","\n","Removed: (1, 1)\n","90.91416931152344\n","\n","\n","Removed: (1, 2)\n","91.03984069824219\n","\n","\n","Removed: (1, 3)\n","91.2106704711914\n","\n","\n","Removed: (1, 4)\n","90.81578063964844\n","\n","\n","Removed: (1, 6)\n","90.76304626464844\n","\n","\n","Removed: (1, 7)\n","90.75548553466797\n","\n","\n","Removed: (1, 8)\n","90.8589096069336\n","\n","\n","Removed: (1, 9)\n","91.19255065917969\n","\n","\n","Removed: (1, 10)\n","91.53892517089844\n","\n","\n","Removed: (1, 11)\n","91.91824340820312\n","\n","\n","Removed: (0, 0)\n","92.5820541381836\n","\n","\n","Removed: (0, 2)\n","90.63056945800781\n","\n","\n","Removed: (0, 4)\n","91.14491271972656\n","\n","\n","Removed: (0, 6)\n","91.14532470703125\n","\n","\n","Removed: (0, 8)\n","90.61016845703125\n","\n","\n","Removed: (0, 11)\n","90.7052230834961\n","\n","\n"]}]},{"cell_type":"markdown","source":["Try this method on greater-than task to see if recovers circuit similar to paper."],"metadata":{"id":"98GKSi7JbMG2"}},{"cell_type":"code","source":["curr_circuit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-mSQqFhksjs","executionInfo":{"status":"ok","timestamp":1696454602793,"user_tz":240,"elapsed":11,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8b8122b7-c93c-40b2-d4fc-19114bfab172"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 3),\n"," (0, 5),\n"," (0, 7),\n"," (0, 9),\n"," (0, 10),\n"," (1, 0),\n"," (1, 5),\n"," (2, 2),\n"," (2, 9),\n"," (3, 0),\n"," (3, 3),\n"," (3, 7),\n"," (4, 4),\n"," (4, 7),\n"," (4, 8),\n"," (4, 10),\n"," (5, 1),\n"," (5, 4),\n"," (5, 5),\n"," (5, 6),\n"," (5, 8),\n"," (5, 9),\n"," (5, 10),\n"," (6, 1),\n"," (6, 3),\n"," (6, 4),\n"," (6, 6),\n"," (6, 10),\n"," (7, 2),\n"," (7, 6),\n"," (7, 10),\n"," (7, 11),\n"," (8, 8),\n"," (9, 1),\n"," (10, 7)]"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["%%capture\n","curr_circuit = find_circuit_backw(20)"],"metadata":{"id":"vp7F1qFGlv-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_circuit"],"metadata":{"id":"Liy24wbtnGF3","executionInfo":{"status":"ok","timestamp":1696455223999,"user_tz":240,"elapsed":8,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"055afbe4-0091-4ca1-bf22-f2d88e8d8653","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 3),\n"," (0, 5),\n"," (0, 9),\n"," (0, 10),\n"," (1, 0),\n"," (1, 5),\n"," (2, 2),\n"," (2, 9),\n"," (3, 0),\n"," (3, 2),\n"," (3, 3),\n"," (3, 7),\n"," (4, 4),\n"," (4, 6),\n"," (4, 7),\n"," (4, 8),\n"," (4, 10),\n"," (5, 0),\n"," (5, 1),\n"," (5, 4),\n"," (5, 5),\n"," (5, 6),\n"," (5, 8),\n"," (5, 9),\n"," (5, 11),\n"," (6, 1),\n"," (6, 6),\n"," (6, 8),\n"," (7, 10),\n"," (7, 11),\n"," (8, 6),\n"," (8, 8),\n"," (9, 1)]"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["## mean ablation the circuit pruned by iterative path patching"],"metadata":{"id":"B2f3O144hLcY"}},{"cell_type":"markdown","source":["From:\n","\n","https://colab.research.google.com/drive/1onREXMNmc9ks0xpwDslUX2pdG0RSYtWS#scrollTo=ehsYSXYO_25N&line=6&uniqifier=1"],"metadata":{"id":"s6Mnv8IYiPWf"}},{"cell_type":"code","source":["test_circ = [(0,1), (3,0), (4,4), (5,5), (5,8), (6,6), (7,11), (9,1)]\n","\n","mean_ablate_by_lst(test_circ, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43ud6cmAhYZ_","executionInfo":{"status":"ok","timestamp":1696504285984,"user_tz":240,"elapsed":2435,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"6ff9682a-db6d-4bc6-d31c-2bccf23852d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 13.2641\n"]},{"output_type":"execute_result","data":{"text/plain":["13.264147758483887"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["From:\n","\n","https://colab.research.google.com/drive/1onREXMNmc9ks0xpwDslUX2pdG0RSYtWS#scrollTo=V8JWdlVokmpL&line=6&uniqifier=1"],"metadata":{"id":"Crz7UTeJkwdZ"}},{"cell_type":"code","source":["test_circ = [(0, 1), (0, 5), (0, 10), (1, 5), (3, 0), (4, 4), (4, 8), (5, 1), (5, 4), (5, 5), (5, 8), (6, 1), (6, 6), (6, 9), (6, 10), (7, 6), (7, 10), (7, 11), (8, 8), (9, 1), (10, 7)]\n","mean_ablate_by_lst(test_circ, model, print_output=True).item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UfNZ8pOUkxZO","executionInfo":{"status":"ok","timestamp":1696504979582,"user_tz":240,"elapsed":2808,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"01ec98bf-ee6f-411f-8ac1-f6cd6c9d8663"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average logit difference (circuit / full) %: 40.4605\n"]},{"output_type":"execute_result","data":{"text/plain":["40.46047592163086"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Prune forwards"],"metadata":{"id":"X3Iera3OlvQL"}},{"cell_type":"code","source":["# Start with full circuit\n","curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","threshold = 3  # This is T, a %. if performance is less than T%, allow its removal\n","\n","for layer in range(0, 12):\n","    for head in range(12):\n","        # Copying the curr_circuit so we can iterate over one and modify the other\n","        copy_circuit = curr_circuit.copy()\n","\n","        # Temporarily removing the current tuple from the copied circuit\n","        copy_circuit.remove((layer, head))\n","\n","        new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","        # print((layer,head), new_score)\n","        # If the result is less than the threshold, remove the tuple from the original list\n","        if (100 - new_score) < threshold:\n","            curr_circuit.remove((layer, head))\n","\n","            print(\"Removed:\", (layer, head))\n","            print(new_score)\n","            print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mipzZtCCl0x5","executionInfo":{"status":"ok","timestamp":1696505574748,"user_tz":240,"elapsed":334240,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"380f3d26-b01b-4465-ff22-c005b2318f4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (0, 0)\n","100.00466918945312\n","\n","\n","Removed: (0, 2)\n","98.07209777832031\n","\n","\n","Removed: (0, 4)\n","97.96208953857422\n","\n","\n","Removed: (0, 6)\n","97.41792297363281\n","\n","\n","Removed: (0, 11)\n","98.04102325439453\n","\n","\n","Removed: (1, 1)\n","97.67564392089844\n","\n","\n","Removed: (1, 2)\n","97.67819213867188\n","\n","\n","Removed: (1, 3)\n","97.88668823242188\n","\n","\n","Removed: (1, 4)\n","97.89542388916016\n","\n","\n","Removed: (1, 6)\n","97.8697509765625\n","\n","\n","Removed: (1, 7)\n","98.2431640625\n","\n","\n","Removed: (1, 8)\n","98.43437194824219\n","\n","\n","Removed: (1, 9)\n","98.68045806884766\n","\n","\n","Removed: (1, 10)\n","98.94314575195312\n","\n","\n","Removed: (1, 11)\n","99.24425506591797\n","\n","\n","Removed: (2, 0)\n","99.28617858886719\n","\n","\n","Removed: (2, 1)\n","100.14505767822266\n","\n","\n","Removed: (2, 2)\n","99.1255111694336\n","\n","\n","Removed: (2, 3)\n","99.42776489257812\n","\n","\n","Removed: (2, 4)\n","99.11087036132812\n","\n","\n","Removed: (2, 5)\n","99.4810562133789\n","\n","\n","Removed: (2, 6)\n","99.1651611328125\n","\n","\n","Removed: (2, 7)\n","98.68614959716797\n","\n","\n","Removed: (2, 8)\n","98.37564086914062\n","\n","\n","Removed: (2, 9)\n","97.45429992675781\n","\n","\n","Removed: (2, 10)\n","97.83071899414062\n","\n","\n","Removed: (2, 11)\n","98.20713806152344\n","\n","\n","Removed: (3, 1)\n","98.52078247070312\n","\n","\n","Removed: (3, 2)\n","97.97946166992188\n","\n","\n","Removed: (3, 4)\n","99.23908233642578\n","\n","\n","Removed: (3, 5)\n","99.33444213867188\n","\n","\n","Removed: (3, 6)\n","97.31168365478516\n","\n","\n","Removed: (3, 8)\n","97.29634094238281\n","\n","\n","Removed: (3, 9)\n","97.32966613769531\n","\n","\n","Removed: (4, 0)\n","97.32807159423828\n","\n","\n","Removed: (4, 1)\n","97.42019653320312\n","\n","\n","Removed: (4, 2)\n","97.26522827148438\n","\n","\n","Removed: (4, 3)\n","97.15790557861328\n","\n","\n","Removed: (4, 5)\n","97.18859100341797\n","\n","\n","Removed: (4, 9)\n","97.07299041748047\n","\n","\n","Removed: (5, 0)\n","98.18523406982422\n","\n","\n","Removed: (5, 1)\n","98.06536865234375\n","\n","\n","Removed: (5, 2)\n","98.16412353515625\n","\n","\n","Removed: (5, 3)\n","98.0406494140625\n","\n","\n","Removed: (5, 6)\n","97.69835662841797\n","\n","\n","Removed: (5, 7)\n","97.76480102539062\n","\n","\n","Removed: (5, 8)\n","98.15023803710938\n","\n","\n","Removed: (5, 10)\n","98.22100067138672\n","\n","\n","Removed: (5, 11)\n","100.37446594238281\n","\n","\n","Removed: (6, 0)\n","100.87584686279297\n","\n","\n","Removed: (6, 2)\n","101.04588317871094\n","\n","\n","Removed: (6, 3)\n","100.36302947998047\n","\n","\n","Removed: (6, 4)\n","99.96580505371094\n","\n","\n","Removed: (6, 5)\n","102.2259521484375\n","\n","\n","Removed: (6, 7)\n","102.18389129638672\n","\n","\n","Removed: (6, 8)\n","101.63899230957031\n","\n","\n","Removed: (6, 9)\n","100.62126159667969\n","\n","\n","Removed: (6, 11)\n","99.97000122070312\n","\n","\n","Removed: (7, 0)\n","98.84768676757812\n","\n","\n","Removed: (7, 1)\n","98.78599548339844\n","\n","\n","Removed: (7, 2)\n","98.15278625488281\n","\n","\n","Removed: (7, 3)\n","99.81928253173828\n","\n","\n","Removed: (7, 4)\n","100.52692413330078\n","\n","\n","Removed: (7, 5)\n","99.48352813720703\n","\n","\n","Removed: (7, 7)\n","98.93083190917969\n","\n","\n","Removed: (7, 8)\n","99.4211196899414\n","\n","\n","Removed: (7, 9)\n","98.86318969726562\n","\n","\n","Removed: (8, 0)\n","97.29025268554688\n","\n","\n","Removed: (8, 3)\n","99.36801147460938\n","\n","\n","Removed: (8, 4)\n","99.35574340820312\n","\n","\n","Removed: (8, 5)\n","98.64588928222656\n","\n","\n","Removed: (8, 7)\n","98.52066040039062\n","\n","\n","Removed: (8, 9)\n","98.78216552734375\n","\n","\n","Removed: (8, 10)\n","98.12757873535156\n","\n","\n","Removed: (8, 11)\n","99.93222045898438\n","\n","\n","Removed: (9, 0)\n","99.98300170898438\n","\n","\n","Removed: (9, 2)\n","100.19903564453125\n","\n","\n","Removed: (9, 3)\n","99.94385528564453\n","\n","\n","Removed: (9, 4)\n","99.79147338867188\n","\n","\n","Removed: (9, 6)\n","99.45172882080078\n","\n","\n","Removed: (9, 7)\n","99.28490447998047\n","\n","\n","Removed: (9, 8)\n","99.31771850585938\n","\n","\n","Removed: (9, 9)\n","100.82984161376953\n","\n","\n","Removed: (9, 10)\n","100.5273208618164\n","\n","\n","Removed: (9, 11)\n","99.93990325927734\n","\n","\n","Removed: (10, 0)\n","99.90935516357422\n","\n","\n","Removed: (10, 1)\n","98.35362243652344\n","\n","\n","Removed: (10, 2)\n","99.8908920288086\n","\n","\n","Removed: (10, 3)\n","100.0014419555664\n","\n","\n","Removed: (10, 4)\n","99.68207550048828\n","\n","\n","Removed: (10, 5)\n","98.68380737304688\n","\n","\n","Removed: (10, 6)\n","98.71052551269531\n","\n","\n","Removed: (10, 8)\n","98.82450103759766\n","\n","\n","Removed: (10, 9)\n","98.92301177978516\n","\n","\n","Removed: (10, 10)\n","99.58069610595703\n","\n","\n","Removed: (10, 11)\n","99.3478012084961\n","\n","\n","Removed: (11, 0)\n","98.64879608154297\n","\n","\n","Removed: (11, 1)\n","98.63351440429688\n","\n","\n","Removed: (11, 2)\n","98.82813262939453\n","\n","\n","Removed: (11, 3)\n","98.91162872314453\n","\n","\n","Removed: (11, 4)\n","99.30661010742188\n","\n","\n","Removed: (11, 5)\n","99.28739929199219\n","\n","\n","Removed: (11, 6)\n","99.25061798095703\n","\n","\n","Removed: (11, 7)\n","99.12737274169922\n","\n","\n","Removed: (11, 8)\n","98.2545166015625\n","\n","\n","Removed: (11, 9)\n","97.97991943359375\n","\n","\n","Removed: (11, 11)\n","98.50849151611328\n","\n","\n"]}]},{"cell_type":"code","source":["curr_circuit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_t_18e3QnBmJ","executionInfo":{"status":"ok","timestamp":1696505574748,"user_tz":240,"elapsed":22,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"83c9a0a2-9e4e-4731-a870-bff74fc76a6f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 3),\n"," (0, 5),\n"," (0, 7),\n"," (0, 8),\n"," (0, 9),\n"," (0, 10),\n"," (1, 0),\n"," (1, 5),\n"," (3, 0),\n"," (3, 3),\n"," (3, 7),\n"," (3, 10),\n"," (3, 11),\n"," (4, 4),\n"," (4, 6),\n"," (4, 7),\n"," (4, 8),\n"," (4, 10),\n"," (4, 11),\n"," (5, 4),\n"," (5, 5),\n"," (5, 9),\n"," (6, 1),\n"," (6, 6),\n"," (6, 10),\n"," (7, 6),\n"," (7, 10),\n"," (7, 11),\n"," (8, 1),\n"," (8, 2),\n"," (8, 6),\n"," (8, 8),\n"," (9, 1),\n"," (9, 5),\n"," (10, 7),\n"," (11, 10)]"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## prune fwds then back iteratively- fns"],"metadata":{"id":"w7bys5l5uleW"}},{"cell_type":"code","source":["def find_circuit_forw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(0, 12):\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","            # print((layer,head), new_score)\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"GTOk3N3evb3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_circuit_backw(curr_circuit=None, threshold=10):\n","    # threshold is T, a %. if performance is less than T%, allow its removal\n","    if curr_circuit == []:\n","        # Start with full circuit\n","        curr_circuit = [(layer, head) for layer in range(12) for head in range(12)]\n","\n","    for layer in range(11, -1, -1):  # go thru all heads in a layer first\n","        for head in range(12):\n","            if (layer, head) not in curr_circuit:\n","                continue\n","\n","            # Copying the curr_circuit so we can iterate over one and modify the other\n","            copy_circuit = curr_circuit.copy()\n","\n","            # Temporarily removing the current tuple from the copied circuit\n","            copy_circuit.remove((layer, head))\n","\n","            new_score = mean_ablate_by_lst(copy_circuit, model, print_output=False).item()\n","\n","            # If the result is less than the threshold, remove the tuple from the original list\n","            if (100 - new_score) < threshold:\n","                curr_circuit.remove((layer, head))\n","\n","                print(\"\\nRemoved:\", (layer, head))\n","                print(new_score)\n","\n","    return curr_circuit, new_score"],"metadata":{"id":"flTHN2eQvapG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_circuit = [(0, 1), (0, 3), (0, 5), (0, 7), (0, 8), (0, 9), (0, 10), (1, 0), (1, 5), (3, 0), (3, 3), (3, 7), (3, 10), (3, 11), (4, 4), (4, 6), (4, 7), (4, 8), (4, 10), (4, 11), (5, 4), (5, 5), (5, 9), (6, 1), (6, 6), (6, 10), (7, 6), (7, 10), (7, 11), (8, 1), (8, 2), (8, 6), (8, 8), (9, 1), (9, 5), (10, 7), (11, 10)]\n","curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XxJjm1yiwPov","executionInfo":{"status":"ok","timestamp":1696609051807,"user_tz":240,"elapsed":87402,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"28508490-e932-4ed1-b8a6-62bd4afafdec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed: (8, 2)\n","98.4662094116211\n","\n","\n","Removed: (3, 10)\n","98.19361877441406\n","\n","\n"]}]},{"cell_type":"code","source":["curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=2)"],"metadata":{"id":"qzb436f1yxax"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### iter fwd backw, threshold 2"],"metadata":{"id":"e8OFeKuxzM3R"}},{"cell_type":"code","source":["threshold = 2\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKZjydkhBfTD","executionInfo":{"status":"ok","timestamp":1696613752100,"user_tz":240,"elapsed":564258,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"158c8dcb-8843-47c3-c419-5e2146e8cedd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","100.00470733642578\n","\n","Removed: (0, 2)\n","98.07218170166016\n","\n","Removed: (0, 11)\n","98.68363952636719\n","\n","Removed: (1, 1)\n","98.21087646484375\n","\n","Removed: (1, 2)\n","98.30923461914062\n","\n","Removed: (1, 3)\n","98.48136901855469\n","\n","Removed: (1, 4)\n","98.44184875488281\n","\n","Removed: (1, 6)\n","98.35868072509766\n","\n","Removed: (1, 7)\n","98.70216369628906\n","\n","Removed: (1, 8)\n","98.81130981445312\n","\n","Removed: (1, 9)\n","99.10165405273438\n","\n","Removed: (1, 10)\n","99.28426361083984\n","\n","Removed: (1, 11)\n","98.32254791259766\n","\n","Removed: (2, 0)\n","98.21942138671875\n","\n","Removed: (2, 1)\n","98.96421813964844\n","\n","Removed: (2, 3)\n","99.10186004638672\n","\n","Removed: (2, 4)\n","98.81763458251953\n","\n","Removed: (2, 5)\n","98.89395141601562\n","\n","Removed: (2, 6)\n","98.6978988647461\n","\n","Removed: (2, 7)\n","98.333984375\n","\n","Removed: (2, 8)\n","98.04685974121094\n","\n","Removed: (2, 10)\n","98.67316436767578\n","\n","Removed: (2, 11)\n","98.90179443359375\n","\n","Removed: (3, 1)\n","99.17343139648438\n","\n","Removed: (3, 2)\n","98.44761657714844\n","\n","Removed: (3, 4)\n","99.8545150756836\n","\n","Removed: (3, 5)\n","99.87609100341797\n","\n","Removed: (3, 6)\n","98.54624938964844\n","\n","Removed: (3, 8)\n","98.34951782226562\n","\n","Removed: (3, 9)\n","98.2344741821289\n","\n","Removed: (4, 0)\n","98.23051452636719\n","\n","Removed: (4, 1)\n","98.30501556396484\n","\n","Removed: (4, 2)\n","98.0479965209961\n","\n","Removed: (4, 3)\n","98.07047271728516\n","\n","Removed: (4, 5)\n","98.08451843261719\n","\n","Removed: (5, 0)\n","98.62218475341797\n","\n","Removed: (5, 1)\n","98.10987854003906\n","\n","Removed: (5, 2)\n","98.44831848144531\n","\n","Removed: (5, 3)\n","98.20502471923828\n","\n","Removed: (5, 6)\n","98.27458190917969\n","\n","Removed: (5, 7)\n","98.34869384765625\n","\n","Removed: (5, 10)\n","98.37565612792969\n","\n","Removed: (5, 11)\n","100.82400512695312\n","\n","Removed: (6, 0)\n","101.2210464477539\n","\n","Removed: (6, 2)\n","101.36893463134766\n","\n","Removed: (6, 3)\n","100.75080871582031\n","\n","Removed: (6, 4)\n","100.28299713134766\n","\n","Removed: (6, 5)\n","102.36653900146484\n","\n","Removed: (6, 7)\n","102.59455108642578\n","\n","Removed: (6, 8)\n","101.70237731933594\n","\n","Removed: (6, 9)\n","100.9928970336914\n","\n","Removed: (6, 11)\n","100.31019592285156\n","\n","Removed: (7, 0)\n","99.166748046875\n","\n","Removed: (7, 1)\n","99.12581634521484\n","\n","Removed: (7, 2)\n","98.46310424804688\n","\n","Removed: (7, 3)\n","100.17391204833984\n","\n","Removed: (7, 4)\n","101.02068328857422\n","\n","Removed: (7, 5)\n","100.37606048583984\n","\n","Removed: (7, 7)\n","99.75090789794922\n","\n","Removed: (7, 8)\n","100.13652801513672\n","\n","Removed: (7, 9)\n","99.6332778930664\n","\n","Removed: (8, 1)\n","98.76978302001953\n","\n","Removed: (8, 2)\n","98.51219177246094\n","\n","Removed: (8, 3)\n","100.3709487915039\n","\n","Removed: (8, 4)\n","100.35680389404297\n","\n","Removed: (8, 5)\n","99.65347290039062\n","\n","Removed: (8, 7)\n","99.77912139892578\n","\n","Removed: (8, 9)\n","100.14398956298828\n","\n","Removed: (8, 10)\n","99.61862182617188\n","\n","Removed: (8, 11)\n","101.52581024169922\n","\n","Removed: (9, 0)\n","101.59696197509766\n","\n","Removed: (9, 2)\n","101.81700134277344\n","\n","Removed: (9, 3)\n","101.33214569091797\n","\n","Removed: (9, 4)\n","101.1006088256836\n","\n","Removed: (9, 6)\n","100.58708190917969\n","\n","Removed: (9, 7)\n","100.41132354736328\n","\n","Removed: (9, 8)\n","100.44564819335938\n","\n","Removed: (9, 9)\n","102.12025451660156\n","\n","Removed: (9, 10)\n","101.80047607421875\n","\n","Removed: (9, 11)\n","101.17610168457031\n","\n","Removed: (10, 0)\n","101.13899230957031\n","\n","Removed: (10, 1)\n","99.58889770507812\n","\n","Removed: (10, 2)\n","101.45478820800781\n","\n","Removed: (10, 3)\n","101.5586929321289\n","\n","Removed: (10, 4)\n","101.20699310302734\n","\n","Removed: (10, 5)\n","100.0509262084961\n","\n","Removed: (10, 6)\n","100.08509063720703\n","\n","Removed: (10, 8)\n","100.23741912841797\n","\n","Removed: (10, 9)\n","100.32723236083984\n","\n","Removed: (10, 10)\n","100.94107818603516\n","\n","Removed: (10, 11)\n","100.69126892089844\n","\n","Removed: (11, 0)\n","99.87207794189453\n","\n","Removed: (11, 1)\n","99.85417938232422\n","\n","Removed: (11, 2)\n","100.04780578613281\n","\n","Removed: (11, 3)\n","100.0937728881836\n","\n","Removed: (11, 4)\n","100.50067138671875\n","\n","Removed: (11, 5)\n","100.48121643066406\n","\n","Removed: (11, 6)\n","100.46443176269531\n","\n","Removed: (11, 7)\n","100.3409652709961\n","\n","Removed: (11, 8)\n","99.47927856445312\n","\n","Removed: (11, 9)\n","99.20600891113281\n","\n","Removed: (11, 10)\n","98.12692260742188\n","\n","Removed: (11, 11)\n","98.5977554321289\n","\n","backw prune, iter  1\n","\n","Removed: (4, 9)\n","98.64276123046875\n","\n","Removed: (3, 11)\n","98.05547332763672\n","\n","Removed: (0, 4)\n","98.75322723388672\n","\n","Removed: (0, 6)\n","98.95439910888672\n","\n","Removed: (0, 8)\n","98.8249282836914\n","\n","fwd prune, iter  2\n","\n","Removed: (2, 9)\n","98.20669555664062\n","\n","backw prune, iter  2\n"]}]},{"cell_type":"code","source":["curr_circuit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET--8aulD8pE","executionInfo":{"status":"ok","timestamp":1696613785823,"user_tz":240,"elapsed":309,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cefa8e17-84ae-422f-cff1-934278585315"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1),\n"," (0, 3),\n"," (0, 5),\n"," (0, 7),\n"," (0, 9),\n"," (0, 10),\n"," (1, 0),\n"," (1, 5),\n"," (2, 2),\n"," (3, 0),\n"," (3, 3),\n"," (3, 7),\n"," (3, 10),\n"," (4, 4),\n"," (4, 6),\n"," (4, 7),\n"," (4, 8),\n"," (4, 10),\n"," (4, 11),\n"," (5, 4),\n"," (5, 5),\n"," (5, 8),\n"," (5, 9),\n"," (6, 1),\n"," (6, 6),\n"," (6, 10),\n"," (7, 6),\n"," (7, 10),\n"," (7, 11),\n"," (8, 0),\n"," (8, 6),\n"," (8, 8),\n"," (9, 1),\n"," (9, 5),\n"," (10, 7)]"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["### iter fwd backw, threshold 25"],"metadata":{"id":"C2fvsn5SFnrO"}},{"cell_type":"code","source":["threshold = 25\n","curr_circuit = []\n","prev_score = 100\n","new_score = 0\n","iter = 1\n","while prev_score != new_score:\n","    print('\\nfwd prune, iter ', str(iter))\n","    # track changes in circuit as for some reason it doesn't work with scores\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_forw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    print('\\nbackw prune, iter ', str(iter))\n","    # prev_score = new_score # save old score before finding new one\n","    old_circuit = curr_circuit.copy() # save old before finding new one\n","    curr_circuit, new_score = find_circuit_backw(curr_circuit=curr_circuit, threshold=threshold)\n","    if curr_circuit == old_circuit:\n","        break\n","    iter += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696614895022,"user_tz":240,"elapsed":493474,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a647fdf8-f9ef-4296-d1bd-c937930031ad","id":"smR_M0B7FnrP"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","fwd prune, iter  1\n","\n","Removed: (0, 0)\n","100.00466918945312\n","\n","Removed: (0, 1)\n","75.59306335449219\n","\n","Removed: (0, 4)\n","75.92542266845703\n","\n","Removed: (0, 7)\n","76.21915435791016\n","\n","Removed: (0, 11)\n","76.85157775878906\n","\n","Removed: (1, 1)\n","75.60380554199219\n","\n","Removed: (1, 2)\n","75.31912994384766\n","\n","Removed: (1, 4)\n","75.96576690673828\n","\n","Removed: (1, 6)\n","76.30498504638672\n","\n","Removed: (1, 7)\n","77.71282958984375\n","\n","Removed: (1, 8)\n","77.05686950683594\n","\n","Removed: (1, 9)\n","77.09788513183594\n","\n","Removed: (1, 10)\n","77.23350524902344\n","\n","Removed: (2, 0)\n","77.10811614990234\n","\n","Removed: (2, 1)\n","77.01587677001953\n","\n","Removed: (2, 2)\n","76.7368392944336\n","\n","Removed: (2, 3)\n","76.66363525390625\n","\n","Removed: (2, 4)\n","76.45865631103516\n","\n","Removed: (2, 5)\n","76.50445556640625\n","\n","Removed: (2, 6)\n","75.87989807128906\n","\n","Removed: (2, 7)\n","76.36524963378906\n","\n","Removed: (2, 8)\n","75.61309051513672\n","\n","Removed: (2, 9)\n","75.46623992919922\n","\n","Removed: (2, 10)\n","76.1516342163086\n","\n","Removed: (2, 11)\n","76.39988708496094\n","\n","Removed: (3, 1)\n","76.32125091552734\n","\n","Removed: (3, 2)\n","76.8115005493164\n","\n","Removed: (3, 4)\n","79.23828887939453\n","\n","Removed: (3, 5)\n","79.31707763671875\n","\n","Removed: (3, 6)\n","77.40769958496094\n","\n","Removed: (3, 8)\n","76.76896667480469\n","\n","Removed: (3, 9)\n","76.71797943115234\n","\n","Removed: (3, 10)\n","75.35568237304688\n","\n","Removed: (4, 0)\n","75.38558197021484\n","\n","Removed: (4, 1)\n","75.58832550048828\n","\n","Removed: (4, 2)\n","75.48287963867188\n","\n","Removed: (4, 3)\n","75.40394592285156\n","\n","Removed: (4, 5)\n","75.42877197265625\n","\n","Removed: (4, 8)\n","75.34091186523438\n","\n","Removed: (4, 9)\n","75.350341796875\n","\n","Removed: (5, 1)\n","75.8497085571289\n","\n","Removed: (5, 2)\n","76.17313385009766\n","\n","Removed: (5, 3)\n","75.97501373291016\n","\n","Removed: (5, 6)\n","76.55963897705078\n","\n","Removed: (5, 7)\n","76.61959838867188\n","\n","Removed: (5, 8)\n","80.12305450439453\n","\n","Removed: (5, 9)\n","79.64529418945312\n","\n","Removed: (5, 10)\n","79.727783203125\n","\n","Removed: (5, 11)\n","81.69183349609375\n","\n","Removed: (6, 0)\n","82.26904296875\n","\n","Removed: (6, 1)\n","76.8419418334961\n","\n","Removed: (6, 2)\n","76.76387023925781\n","\n","Removed: (6, 3)\n","76.37213897705078\n","\n","Removed: (6, 4)\n","76.4698486328125\n","\n","Removed: (6, 5)\n","78.66380310058594\n","\n","Removed: (6, 7)\n","77.8857650756836\n","\n","Removed: (6, 8)\n","76.94995880126953\n","\n","Removed: (6, 9)\n","75.45603942871094\n","\n","Removed: (7, 1)\n","75.39861297607422\n","\n","Removed: (7, 3)\n","76.93096160888672\n","\n","Removed: (7, 4)\n","77.76341247558594\n","\n","Removed: (7, 5)\n","77.12254333496094\n","\n","Removed: (7, 7)\n","76.46027374267578\n","\n","Removed: (7, 8)\n","77.0417709350586\n","\n","Removed: (7, 9)\n","76.48628997802734\n","\n","Removed: (8, 0)\n","76.91979217529297\n","\n","Removed: (8, 1)\n","75.53549194335938\n","\n","Removed: (8, 2)\n","75.0972900390625\n","\n","Removed: (8, 3)\n","77.04907989501953\n","\n","Removed: (8, 4)\n","77.05741119384766\n","\n","Removed: (8, 5)\n","76.59270477294922\n","\n","Removed: (8, 7)\n","76.65808868408203\n","\n","Removed: (8, 9)\n","77.19325256347656\n","\n","Removed: (8, 10)\n","76.95560455322266\n","\n","Removed: (8, 11)\n","75.33029174804688\n","\n","Removed: (9, 0)\n","75.406005859375\n","\n","Removed: (9, 2)\n","75.62068176269531\n","\n","Removed: (9, 3)\n","75.85317993164062\n","\n","Removed: (9, 4)\n","75.67760467529297\n","\n","Removed: (9, 6)\n","75.15196990966797\n","\n","Removed: (9, 7)\n","75.02926635742188\n","\n","Removed: (9, 8)\n","75.0541763305664\n","\n","Removed: (9, 9)\n","78.16915893554688\n","\n","Removed: (9, 10)\n","77.9127426147461\n","\n","Removed: (9, 11)\n","77.3892822265625\n","\n","Removed: (10, 0)\n","77.36613464355469\n","\n","Removed: (10, 1)\n","76.15100860595703\n","\n","Removed: (10, 2)\n","77.95581817626953\n","\n","Removed: (10, 3)\n","78.06468963623047\n","\n","Removed: (10, 4)\n","77.73857116699219\n","\n","Removed: (10, 5)\n","76.99889373779297\n","\n","Removed: (10, 6)\n","77.0383529663086\n","\n","Removed: (10, 8)\n","77.13395690917969\n","\n","Removed: (10, 9)\n","77.36073303222656\n","\n","Removed: (10, 10)\n","77.90914916992188\n","\n","Removed: (10, 11)\n","77.74614715576172\n","\n","Removed: (11, 0)\n","77.10027313232422\n","\n","Removed: (11, 1)\n","77.09026336669922\n","\n","Removed: (11, 2)\n","77.27554321289062\n","\n","Removed: (11, 3)\n","77.27286529541016\n","\n","Removed: (11, 4)\n","77.67971801757812\n","\n","Removed: (11, 5)\n","77.65947723388672\n","\n","Removed: (11, 6)\n","77.6371841430664\n","\n","Removed: (11, 7)\n","77.50538635253906\n","\n","Removed: (11, 8)\n","76.8567123413086\n","\n","Removed: (11, 9)\n","76.67324829101562\n","\n","Removed: (11, 10)\n","75.54029083251953\n","\n","Removed: (11, 11)\n","75.69001770019531\n","\n","backw prune, iter  1\n","\n","Removed: (7, 2)\n","75.057373046875\n","\n","Removed: (5, 0)\n","75.9627914428711\n","\n","Removed: (5, 4)\n","75.07794952392578\n","\n","Removed: (1, 3)\n","75.1583251953125\n","\n","fwd prune, iter  2\n"]}]},{"cell_type":"code","source":["curr_circuit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696614895023,"user_tz":240,"elapsed":28,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"ad41beb9-0952-40dd-aff6-40fff4649d6b","id":"78x6pmqkFnrP"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 2),\n"," (0, 3),\n"," (0, 5),\n"," (0, 6),\n"," (0, 8),\n"," (0, 9),\n"," (0, 10),\n"," (1, 0),\n"," (1, 5),\n"," (1, 11),\n"," (3, 0),\n"," (3, 3),\n"," (3, 7),\n"," (3, 11),\n"," (4, 4),\n"," (4, 6),\n"," (4, 7),\n"," (4, 10),\n"," (4, 11),\n"," (5, 5),\n"," (6, 6),\n"," (6, 10),\n"," (6, 11),\n"," (7, 0),\n"," (7, 6),\n"," (7, 10),\n"," (7, 11),\n"," (8, 6),\n"," (8, 8),\n"," (9, 1),\n"," (9, 5),\n"," (10, 7)]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## etc fns"],"metadata":{"id":"8293qqJoGlA_"}},{"cell_type":"code","source":["# base_lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7)]"],"metadata":{"id":"VaxbugcfGlBA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import json\n","\n","# with open(\"scores.json\", \"w\") as file:\n","#     json.dump(all_scores, file, default=lambda x: str(x))  # Convert tuples to strings for JSON serialization"],"metadata":{"id":"UNTjGSd4U1r5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from google.colab import files\n","# files.download(\"scores.json\")  # or \"scores.pkl\" or \"scores.json\" depending on the file you saved"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1696198883995,"user_tz":240,"elapsed":15,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"41cf8973-e8ea-4796-c7e4-6c97d0724164","id":"wUEqYKZ5U1r6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f15d2ec7-9d13-41b6-9dc7-e441269e1323\", \"one_head_added_scores.json\", 4770)"]},"metadata":{}}]}]}