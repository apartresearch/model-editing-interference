{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","collapsed_sections":["DcZG9rm2IAiA","6Fuq8XW770vX","cvDoLG2YR73k","NXLKleFoSQMO","StWTdvI1hz4H","pJ804aWuhqu8","JSQkrPMHiJYI","TVyYiX9DZh3V","-D7DD-WPZzQr"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2490dda7d62249e6a6abe895353ed94f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d69c41bbb8434161983fbfc39798a9f7","IPY_MODEL_3b7a934b7c7a49568902e2930eabb22c","IPY_MODEL_35c7cdd2c32749ecb8db143d110698ad"],"layout":"IPY_MODEL_a85b86f47f2743539670ae196c9f74d1"}},"d69c41bbb8434161983fbfc39798a9f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8839dbc1074e45c6b9a20fa2d657e5d6","placeholder":"​","style":"IPY_MODEL_bc4610e310b842ca91f089ef9c59f01f","value":"config.json: 100%"}},"3b7a934b7c7a49568902e2930eabb22c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19fc5e4b3b6f429dabb0dea3ddc391de","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b29d1fe797584150830a822116b6aa45","value":665}},"35c7cdd2c32749ecb8db143d110698ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd4b94d9bc95474285f14eff2cbf6369","placeholder":"​","style":"IPY_MODEL_d64174678df448dd8f029ae86367aa6c","value":" 665/665 [00:00&lt;00:00, 3.69kB/s]"}},"a85b86f47f2743539670ae196c9f74d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8839dbc1074e45c6b9a20fa2d657e5d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc4610e310b842ca91f089ef9c59f01f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19fc5e4b3b6f429dabb0dea3ddc391de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b29d1fe797584150830a822116b6aa45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd4b94d9bc95474285f14eff2cbf6369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d64174678df448dd8f029ae86367aa6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3dabe317c8ec44dbb694082a290a4a9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_747a756bd64e4348b26f0b5656251f61","IPY_MODEL_ed93720ac85c49a98a994e0ecc409836","IPY_MODEL_84f0f70760804a4aaf43c6370e55e986"],"layout":"IPY_MODEL_576583b414a041dd910c3ab7c0ad988f"}},"747a756bd64e4348b26f0b5656251f61":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c73f50f8c374fbd9569d40246967e0a","placeholder":"​","style":"IPY_MODEL_c38fd3c975c342d38b08c8597c46d7bb","value":"model.safetensors: 100%"}},"ed93720ac85c49a98a994e0ecc409836":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35e955ff7819466fa002df3c8c0a8c39","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b82479165c4416893611229b0e42e69","value":548105171}},"84f0f70760804a4aaf43c6370e55e986":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be338a061fec42a8bbeefccd17e554ea","placeholder":"​","style":"IPY_MODEL_e38e0a0a059e4c70b91b368b32fc9de6","value":" 548M/548M [00:07&lt;00:00, 195MB/s]"}},"576583b414a041dd910c3ab7c0ad988f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c73f50f8c374fbd9569d40246967e0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c38fd3c975c342d38b08c8597c46d7bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35e955ff7819466fa002df3c8c0a8c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b82479165c4416893611229b0e42e69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be338a061fec42a8bbeefccd17e554ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e38e0a0a059e4c70b91b368b32fc9de6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da3897700cbf49b590e2d54dfa6c83ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d1211e422bf4c9789c818c3044af9c3","IPY_MODEL_561e12524eef4979b287797522095bae","IPY_MODEL_0df05b4ca0d64f7c9033757707c11e04"],"layout":"IPY_MODEL_5e02a9608ff74f1fa944297795b55079"}},"6d1211e422bf4c9789c818c3044af9c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e0d1fff17a54c95a47bda7a10efb6d0","placeholder":"​","style":"IPY_MODEL_0dcf8b48c7b24c7cb4052b47da63de05","value":"generation_config.json: 100%"}},"561e12524eef4979b287797522095bae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_432a360380a74e879e7434f5951d9d28","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_078a2fee553e4306934cf2de8dabc97b","value":124}},"0df05b4ca0d64f7c9033757707c11e04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0a4fe4e9d604c63ba8009c10a6f951f","placeholder":"​","style":"IPY_MODEL_40270ca6574844f1b555fb763b0c8af8","value":" 124/124 [00:00&lt;00:00, 11.0kB/s]"}},"5e02a9608ff74f1fa944297795b55079":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e0d1fff17a54c95a47bda7a10efb6d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dcf8b48c7b24c7cb4052b47da63de05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"432a360380a74e879e7434f5951d9d28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"078a2fee553e4306934cf2de8dabc97b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0a4fe4e9d604c63ba8009c10a6f951f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40270ca6574844f1b555fb763b0c8af8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7b322bde32b4dee902442be249a467b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8f9488e8d784253a64ac0c543ca8409","IPY_MODEL_6b2c9cafe11b43409a999d65d276b755","IPY_MODEL_6e884fdb459b42b5b9fcb7438d10635b"],"layout":"IPY_MODEL_0a697a349b8042e4bc45d3d039e07fd0"}},"f8f9488e8d784253a64ac0c543ca8409":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aac55b65d5da4c3bab297aabbf20a89c","placeholder":"​","style":"IPY_MODEL_4c53ace93caf44b8b3330b4c45c9cfe3","value":"tokenizer_config.json: 100%"}},"6b2c9cafe11b43409a999d65d276b755":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c87b02f29e88497c8d1a83d7b70d9e07","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d87d5939d4ba4a2197c618667ad485f1","value":26}},"6e884fdb459b42b5b9fcb7438d10635b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_998438ef2f5842e7903ff69a0ecde37e","placeholder":"​","style":"IPY_MODEL_dd3b751a8bc548408a98d41d8f493587","value":" 26.0/26.0 [00:00&lt;00:00, 2.02kB/s]"}},"0a697a349b8042e4bc45d3d039e07fd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aac55b65d5da4c3bab297aabbf20a89c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c53ace93caf44b8b3330b4c45c9cfe3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c87b02f29e88497c8d1a83d7b70d9e07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d87d5939d4ba4a2197c618667ad485f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"998438ef2f5842e7903ff69a0ecde37e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd3b751a8bc548408a98d41d8f493587":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70b290bad7c946149494d3c255312499":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_057f8da140ab4527b05594d341a357b1","IPY_MODEL_2657830486e04ce7825e1e7238d94ba9","IPY_MODEL_bb285fbcaa574b6f8ff80dfbf448dda7"],"layout":"IPY_MODEL_4825b7febd5a4c10a622e8c336b7dc9c"}},"057f8da140ab4527b05594d341a357b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ebcbc48ef47411181abd8b2dce55533","placeholder":"​","style":"IPY_MODEL_3dd8d6b8cc92496583bdd67f79349ebb","value":"vocab.json: 100%"}},"2657830486e04ce7825e1e7238d94ba9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee3b2ea168d3400e8d76f2c3bfb8c97c","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53ace36fb470475b9bebf8c7e7f3af5d","value":1042301}},"bb285fbcaa574b6f8ff80dfbf448dda7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e43de0a9b4b44ffb4ad6a734fa5d8f3","placeholder":"​","style":"IPY_MODEL_fe94d1515c854787bd556694e9a81e74","value":" 1.04M/1.04M [00:00&lt;00:00, 5.86MB/s]"}},"4825b7febd5a4c10a622e8c336b7dc9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ebcbc48ef47411181abd8b2dce55533":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dd8d6b8cc92496583bdd67f79349ebb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee3b2ea168d3400e8d76f2c3bfb8c97c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53ace36fb470475b9bebf8c7e7f3af5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e43de0a9b4b44ffb4ad6a734fa5d8f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe94d1515c854787bd556694e9a81e74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb25109d0ace4d9d91a11060e5c2ead8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_abacffe5814d412abf65fb66044c0a06","IPY_MODEL_dc010adc154445baa35bb9ec0b21a6ec","IPY_MODEL_0c6b8b92be534ab2978153a9d147935e"],"layout":"IPY_MODEL_fcfe045b07b548c1b54c1e29aa3cc85f"}},"abacffe5814d412abf65fb66044c0a06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a687bcca7c44b678ea38713e017c632","placeholder":"​","style":"IPY_MODEL_913b33ea0f70484e8f508bd34101d878","value":"merges.txt: 100%"}},"dc010adc154445baa35bb9ec0b21a6ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e04484df2df4135b1292d2a9d00738a","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6fc4b46d0f84ba982aa1a3ddd7ca78a","value":456318}},"0c6b8b92be534ab2978153a9d147935e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ffe3fc70dca4b2c8da273cf1909f4e4","placeholder":"​","style":"IPY_MODEL_ce05d4a9f7c34023882b46302e3a8981","value":" 456k/456k [00:00&lt;00:00, 882kB/s]"}},"fcfe045b07b548c1b54c1e29aa3cc85f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a687bcca7c44b678ea38713e017c632":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"913b33ea0f70484e8f508bd34101d878":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e04484df2df4135b1292d2a9d00738a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6fc4b46d0f84ba982aa1a3ddd7ca78a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ffe3fc70dca4b2c8da273cf1909f4e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce05d4a9f7c34023882b46302e3a8981":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82f284649b364add8cae58590decb52b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90f008ea92a84a16951277f6a7c477e9","IPY_MODEL_04c9a1b337ef4e929fb6073dd55dd4ce","IPY_MODEL_a206aa4c00ce49f890d2077b1d95ef9c"],"layout":"IPY_MODEL_7b2bd5f91076457c9f7780c898728695"}},"90f008ea92a84a16951277f6a7c477e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_984e8d05da654a3995491dee3694caac","placeholder":"​","style":"IPY_MODEL_b8ebdcb10cb0493eb96eaf7109c0fb66","value":"tokenizer.json: 100%"}},"04c9a1b337ef4e929fb6073dd55dd4ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_706bf45710434162b15b432796e3d9ce","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15a019e50d934e88b42b7b4d4a6a8475","value":1355256}},"a206aa4c00ce49f890d2077b1d95ef9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a1f53ae9f9348f4a8bebed7733e7af7","placeholder":"​","style":"IPY_MODEL_1f90b826eea54bb2b0ff0c605818ad73","value":" 1.36M/1.36M [00:00&lt;00:00, 1.60MB/s]"}},"7b2bd5f91076457c9f7780c898728695":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"984e8d05da654a3995491dee3694caac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8ebdcb10cb0493eb96eaf7109c0fb66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"706bf45710434162b15b432796e3d9ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15a019e50d934e88b42b7b4d4a6a8475":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a1f53ae9f9348f4a8bebed7733e7af7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f90b826eea54bb2b0ff0c605818ad73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DcZG9rm2IAiA"},"source":["# Setup"]},{"cell_type":"markdown","source":["## Change Inputs Here"],"metadata":{"id":"vKYgaZ9JjihZ"}},{"cell_type":"code","source":["model_name = \"gpt2-small\"\n","save_files = True"],"metadata":{"id":"KSKP_OsTDki6","executionInfo":{"status":"ok","timestamp":1728032496722,"user_tz":240,"elapsed":578,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["%%capture\n","%pip install git+https://github.com/neelnanda-io/TransformerLens.git"],"metadata":{"id":"F1wsEy0MqHU0","executionInfo":{"status":"ok","timestamp":1728032514014,"user_tz":240,"elapsed":16597,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Z6b1n2tvIAiD","executionInfo":{"status":"ok","timestamp":1728032518645,"user_tz":240,"elapsed":4636,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","from fancy_einsum import einsum\n","import tqdm.notebook as tqdm\n","import random\n","from pathlib import Path\n","# import plotly.express as px\n","from torch.utils.data import DataLoader\n","\n","from jaxtyping import Float, Int\n","from typing import List, Union, Optional\n","from functools import partial\n","import copy\n","\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","from IPython.display import HTML\n","\n","import pickle\n","from google.colab import files\n","\n","import matplotlib.pyplot as plt\n","import statistics"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zuhzYxbsIAiE","executionInfo":{"status":"ok","timestamp":1728032520039,"user_tz":240,"elapsed":1412,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["import transformer_lens\n","import transformer_lens.utils as utils\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"]},{"cell_type":"markdown","metadata":{"id":"hccba0v-IAiF"},"source":["We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."]},{"cell_type":"code","source":["import pdb"],"metadata":{"id":"bQr6WtEppHgy","executionInfo":{"status":"ok","timestamp":1728032520039,"user_tz":240,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OLkInsdjyHMx"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"cFMTUcQiIAiF","executionInfo":{"status":"ok","timestamp":1728032520039,"user_tz":240,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["torch.set_grad_enabled(False)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"xLwDyosvIAiJ","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["2490dda7d62249e6a6abe895353ed94f","d69c41bbb8434161983fbfc39798a9f7","3b7a934b7c7a49568902e2930eabb22c","35c7cdd2c32749ecb8db143d110698ad","a85b86f47f2743539670ae196c9f74d1","8839dbc1074e45c6b9a20fa2d657e5d6","bc4610e310b842ca91f089ef9c59f01f","19fc5e4b3b6f429dabb0dea3ddc391de","b29d1fe797584150830a822116b6aa45","cd4b94d9bc95474285f14eff2cbf6369","d64174678df448dd8f029ae86367aa6c","3dabe317c8ec44dbb694082a290a4a9f","747a756bd64e4348b26f0b5656251f61","ed93720ac85c49a98a994e0ecc409836","84f0f70760804a4aaf43c6370e55e986","576583b414a041dd910c3ab7c0ad988f","3c73f50f8c374fbd9569d40246967e0a","c38fd3c975c342d38b08c8597c46d7bb","35e955ff7819466fa002df3c8c0a8c39","3b82479165c4416893611229b0e42e69","be338a061fec42a8bbeefccd17e554ea","e38e0a0a059e4c70b91b368b32fc9de6","da3897700cbf49b590e2d54dfa6c83ef","6d1211e422bf4c9789c818c3044af9c3","561e12524eef4979b287797522095bae","0df05b4ca0d64f7c9033757707c11e04","5e02a9608ff74f1fa944297795b55079","5e0d1fff17a54c95a47bda7a10efb6d0","0dcf8b48c7b24c7cb4052b47da63de05","432a360380a74e879e7434f5951d9d28","078a2fee553e4306934cf2de8dabc97b","f0a4fe4e9d604c63ba8009c10a6f951f","40270ca6574844f1b555fb763b0c8af8","c7b322bde32b4dee902442be249a467b","f8f9488e8d784253a64ac0c543ca8409","6b2c9cafe11b43409a999d65d276b755","6e884fdb459b42b5b9fcb7438d10635b","0a697a349b8042e4bc45d3d039e07fd0","aac55b65d5da4c3bab297aabbf20a89c","4c53ace93caf44b8b3330b4c45c9cfe3","c87b02f29e88497c8d1a83d7b70d9e07","d87d5939d4ba4a2197c618667ad485f1","998438ef2f5842e7903ff69a0ecde37e","dd3b751a8bc548408a98d41d8f493587","70b290bad7c946149494d3c255312499","057f8da140ab4527b05594d341a357b1","2657830486e04ce7825e1e7238d94ba9","bb285fbcaa574b6f8ff80dfbf448dda7","4825b7febd5a4c10a622e8c336b7dc9c","9ebcbc48ef47411181abd8b2dce55533","3dd8d6b8cc92496583bdd67f79349ebb","ee3b2ea168d3400e8d76f2c3bfb8c97c","53ace36fb470475b9bebf8c7e7f3af5d","5e43de0a9b4b44ffb4ad6a734fa5d8f3","fe94d1515c854787bd556694e9a81e74","bb25109d0ace4d9d91a11060e5c2ead8","abacffe5814d412abf65fb66044c0a06","dc010adc154445baa35bb9ec0b21a6ec","0c6b8b92be534ab2978153a9d147935e","fcfe045b07b548c1b54c1e29aa3cc85f","8a687bcca7c44b678ea38713e017c632","913b33ea0f70484e8f508bd34101d878","0e04484df2df4135b1292d2a9d00738a","c6fc4b46d0f84ba982aa1a3ddd7ca78a","9ffe3fc70dca4b2c8da273cf1909f4e4","ce05d4a9f7c34023882b46302e3a8981","82f284649b364add8cae58590decb52b","90f008ea92a84a16951277f6a7c477e9","04c9a1b337ef4e929fb6073dd55dd4ce","a206aa4c00ce49f890d2077b1d95ef9c","7b2bd5f91076457c9f7780c898728695","984e8d05da654a3995491dee3694caac","b8ebdcb10cb0493eb96eaf7109c0fb66","706bf45710434162b15b432796e3d9ce","15a019e50d934e88b42b7b4d4a6a8475","2a1f53ae9f9348f4a8bebed7733e7af7","1f90b826eea54bb2b0ff0c605818ad73"],"height":417},"executionInfo":{"status":"ok","timestamp":1728032537924,"user_tz":240,"elapsed":17888,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"032ef74d-33ca-40cc-ee8f-12d743326251"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2490dda7d62249e6a6abe895353ed94f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dabe317c8ec44dbb694082a290a4a9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da3897700cbf49b590e2d54dfa6c83ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7b322bde32b4dee902442be249a467b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70b290bad7c946149494d3c255312499"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb25109d0ace4d9d91a11060e5c2ead8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82f284649b364add8cae58590decb52b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]}],"source":["model = HookedTransformer.from_pretrained(\n","    model_name,\n","    center_unembed=True,\n","    center_writing_weights=True,\n","    fold_ln=True,\n","    refactor_factored_attn_matrices=True,\n",")"]},{"cell_type":"markdown","source":["## Import functions from repo"],"metadata":{"id":"Z4iJEGh6b56v"}},{"cell_type":"code","source":["!git clone https://github.com/apartresearch/seqcont_circuits.git\n","%cd /content/seqcont_circuits/src/iter_node_pruning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728032540596,"user_tz":240,"elapsed":2676,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"34375394-6222-4aae-f1f1-a21fe54208c0","id":"F8TXMRL3CoPd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'seqcont_circuits'...\n","remote: Enumerating objects: 1069, done.\u001b[K\n","remote: Counting objects: 100% (535/535), done.\u001b[K\n","remote: Compressing objects: 100% (312/312), done.\u001b[K\n","remote: Total 1069 (delta 336), reused 403 (delta 212), pack-reused 534 (from 1)\u001b[K\n","Receiving objects: 100% (1069/1069), 19.61 MiB | 19.52 MiB/s, done.\n","Resolving deltas: 100% (699/699), done.\n","/content/seqcont_circuits/src/iter_node_pruning\n"]}]},{"cell_type":"code","source":["## comment this out when debugging functions in colab to use funcs defined in colab\n","\n","# don't improt this\n","# # from dataset import Dataset\n","\n","from metrics import *\n","from head_ablation_fns import *\n","from mlp_ablation_fns import *\n","from node_ablation_fns import *\n","from loop_node_ablation_fns import *"],"metadata":{"id":"22TI4zjMDMfQ","executionInfo":{"status":"ok","timestamp":1728032540596,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## fns"],"metadata":{"id":"9R_g1Ghv7cGE"}},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, prompts, pos_dict, tokenizer):  # , S1_is_first=False\n","        self.prompts = prompts\n","        self.tokenizer = tokenizer\n","        self.N = len(prompts)\n","        self.max_len = max(\n","            [\n","                len(self.tokenizer(prompt[\"text\"]).input_ids)\n","                for prompt in self.prompts\n","            ]\n","        )\n","        all_ids = [0 for prompt in self.prompts] # only 1 template\n","        all_ids_ar = np.array(all_ids)\n","        self.groups = []\n","        for id in list(set(all_ids)):\n","            self.groups.append(np.where(all_ids_ar == id)[0])\n","\n","        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n","        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n","            torch.int\n","        )\n","        self.corr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"corr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"corr\"])[0] for prompt in self.prompts\n","        ]\n","        self.incorr_tokenIDs = [\n","            # self.tokenizer.encode(\" \" + prompt[\"incorr\"])[0] for prompt in self.prompts\n","            self.tokenizer.encode(prompt[\"incorr\"])[0] for prompt in self.prompts\n","        ]\n","\n","        # word_idx: for every prompt, find the token index of each target token and \"end\"\n","        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n","        self.word_idx = {}\n","        # for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'corr' and key != 'incorr')]:\n","        for targ in [key for key in pos_dict]:\n","            targ_lst = []\n","            for prompt in self.prompts:\n","                input_text = prompt[\"text\"]\n","                tokens = self.tokenizer.tokenize(input_text)\n","                # if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n","                #     target_token = prompt[targ]\n","                # else:\n","                #     target_token = \"Ġ\" + prompt[targ]\n","                # target_index = tokens.index(target_token)\n","                target_index = pos_dict[targ]\n","                targ_lst.append(target_index)\n","            self.word_idx[targ] = torch.tensor(targ_lst)\n","\n","        targ_lst = []\n","        for prompt in self.prompts:\n","            input_text = prompt[\"text\"]\n","            tokens = self.tokenizer.tokenize(input_text)\n","            end_token_index = len(tokens) - 1\n","            targ_lst.append(end_token_index)\n","        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n","\n","    def __len__(self):\n","        return self.N"],"metadata":{"id":"6NPjHv-Xny4R","executionInfo":{"status":"ok","timestamp":1728032540596,"user_tz":240,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def generate_prompts_list_longer(text, tokens):\n","    prompts_list = []\n","    prompt_dict = {\n","        'corr': str(1),\n","        'incorr': str(2),\n","        'text': text}\n","    tokens_as_strs = model.tokenizer.tokenize(text)\n","    # for i in range(tokens.shape[1]):\n","    for i, tok in enumerate(tokens_as_strs):\n","        prompt_dict['S'+str(i)] = tok\n","    prompts_list.append(prompt_dict)\n","    return prompts_list"],"metadata":{"id":"VZKVG778QYyn","executionInfo":{"status":"ok","timestamp":1728032540597,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Load datasets"],"metadata":{"id":"6Fuq8XW770vX"}},{"cell_type":"code","source":["def generate_prompts_list(x ,y):\n","    prompts_list = []\n","    for i in range(x, y):\n","        prompt_dict = {\n","            'S1': str(i),\n","            'S2': str(i+1),\n","            'S3': str(i+2),\n","            'S4': str(i+3),\n","            'corr': str(i+4),\n","            'incorr': str(i+3),\n","            'text': f\"{i} {i+1} {i+2} {i+3}\"\n","        }\n","        prompts_list.append(prompt_dict)\n","    return prompts_list\n","\n","prompts_list = generate_prompts_list(1, 2)\n","prompts_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IvAkKJI06Vt5","executionInfo":{"status":"ok","timestamp":1728032540597,"user_tz":240,"elapsed":7,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1eb2b328-ee51-4e78-e449-926cc87f931e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'S1': '1',\n","  'S2': '2',\n","  'S3': '3',\n","  'S4': '4',\n","  'corr': '5',\n","  'incorr': '4',\n","  'text': '1 2 3 4'}]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["pos_dict = {}\n","for i in range(len(model.tokenizer.tokenize(prompts_list[0]['text']))):\n","    pos_dict['S'+str(i)] = i"],"metadata":{"id":"kS_Tlrb_70vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = Dataset(prompts_list, pos_dict, model.tokenizer)"],"metadata":{"id":"u0NPSKcZ1iDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_prompts_list_corr(prompt_list):\n","    outlist = []\n","    # for i in range(100):\n","    for prompt_dict in prompts_list:\n","        r1 = random.randint(1, 12)\n","        r2 = random.randint(1, 12)\n","        while True:\n","            r3 = random.randint(1, 12)\n","            r4 = random.randint(1, 12)\n","            if r4 - 1 != r3:\n","                break\n","        new_text = prompt_dict['text'].replace(prompt_dict['S1'], str(r1)).replace(prompt_dict['S2'], str(r2)).replace(prompt_dict['S3'], str(r3)).replace(prompt_dict['S4'], str(r4))\n","        new_prompt_dict = {\n","            'S1': str(r1),\n","            'S2': str(r2),\n","            'S3': str(r3),\n","            'S4': str(r4),\n","            'corr': prompt_dict['corr'],\n","            'incorr': prompt_dict['incorr'],\n","            'text': new_text\n","        }\n","        outlist.append(new_prompt_dict)\n","    return outlist\n","prompts_list_2 = generate_prompts_list_corr(prompts_list)\n","len(prompts_list_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Jtstw1o7Gkj","executionInfo":{"status":"ok","timestamp":1728032540597,"user_tz":240,"elapsed":6,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"de390909-1b96-47af-a83c-f672503092d3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)"],"metadata":{"id":"msu6D4p_feW5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get orig score"],"metadata":{"id":"BHHvz84w70vh"}},{"cell_type":"code","source":["model.reset_hooks(including_permanent=True)\n","logits_original = model(dataset.toks)\n","orig_score = get_logit_diff(logits_original, dataset)\n","orig_score"],"metadata":{"id":"OI3FcmpMaNxB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728032541602,"user_tz":240,"elapsed":1009,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a1e6c332-9a82-4650-f3b0-f8db3a46597d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6.0631, device='cuda:0')"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["import gc\n","\n","del(logits_original)\n","torch.cuda.empty_cache()\n","gc.collect()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1728032541603,"user_tz":240,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"A-TjmW5PUwGC","outputId":"589fea80-de6d-4dc0-a52a-b4b922425426"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["35"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# logit diff for mult tok answers"],"metadata":{"id":"jtaV1q3SBHow"}},{"cell_type":"code","source":["def clean_gen(model, clean_text, corr_ans):\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    tokens = model.to_tokens(clean_text).to(device)\n","    tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","\n","    total_score = 0\n","    corr_ans_tokLen = 0\n","    ans_so_far = ''\n","    # while True:\n","    for i in range(5):\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        dataset = Dataset(prompts_list, pos_dict, model.tokenizer)\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","\n","        # measure how far away predicted logit is from corr token?\n","\n","        # corr_logits = logits[:, dataset.word_idx[\"end\"], dataset.corr_tokenIDs]\n","        # incorr_logits = logits[:, dataset.word_idx[\"end\"], dataset.incorr_tokenIDs]\n","        # new_score = corr_logits - incorr_logits\n","\n","        corr_logits = logits[:, -1, next_token]\n","        total_score += corr_logits\n","        print(f\"logit diff of new char: {corr_logits}\")\n","\n","        ans_so_far += next_char\n","        corr_ans_tokLen += 1\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","        if ans_so_far == corr_ans:\n","            print('\\nTotal logit diff: ', total_score.item())\n","            break\n","        # Define new input sequence, by appending the previously generated token\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","    return corr_ans_tokLen"],"metadata":{"id":"WgbtY5fFPb71","executionInfo":{"status":"ok","timestamp":1728032541603,"user_tz":240,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["clean_text = \"1 2 3 4\"\n","corr_ans = ' 5'\n","corr_ans_tokLen = clean_gen(model, clean_text, corr_ans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7ScEnVdeJwD","executionInfo":{"status":"ok","timestamp":1728032541603,"user_tz":240,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"1ac98717-9308-40e7-b298-07f60551a801"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3 4'\n","logit diff of new char: tensor([16.8118], device='cuda:0')\n","5th char = ' 5'\n","\n","Total logit diff:  16.811798095703125\n"]}]},{"cell_type":"code","source":["def ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","    logits = model(tokens)\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","\n","    print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","    for i in range(corr_ans_tokLen):\n","    # for i in range(5):\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        clean_text = clean_text + next_char\n","        tokens = model.to_tokens(clean_text).to(device)\n","        tokens = tokens[:, 1:]\n","        print(clean_text)\n","\n","        # get new ablation dataset\n","        model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        corr_text = corr_text + next_char\n","        corr_tokens = model.to_tokens(corr_text).to(device)\n","        prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","        print(corr_text)\n","\n","        pos_dict = {}\n","        for i in range(len(model.tokenizer.tokenize(prompts_list_2[0]['text']))):\n","            pos_dict['S'+str(i)] = i\n","\n","        dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","\n","        model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        print('\\n')\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","\n","        new_score = get_logit_diff(logits, dataset)\n","        total_score += new_score\n","        print(f\"corr logit of new char: {new_score}\")\n","    print('\\n Total corr logit: ', total_score.item())"],"metadata":{"id":"lp4MyZ52cUTK","executionInfo":{"status":"ok","timestamp":1728032542191,"user_tz":240,"elapsed":591,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["clean_text = \"1 2 3\"\n","corr_text = \"5 3 9\"\n","heads_not_ablate = []  # ablate all heads but not MLPs\n","mlps_not_ablate = []  # ablate all MLPs\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmBaWRhCctue","executionInfo":{"status":"ok","timestamp":1728032543318,"user_tz":240,"elapsed":1129,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5cd4980f-5a0b-492c-9c9e-4215d3515b44"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = '.'\n","1 2 3.\n","5 3 9.\n","\n","\n","Sequence so far: '1 2 3.'\n","corr logit of new char: 0.8616600036621094\n","\n"," Total corr logit:  0.8616600036621094\n"]}]},{"cell_type":"markdown","source":["# new ablation functions"],"metadata":{"id":"dsdvChbcvgp5"}},{"cell_type":"code","source":["def get_heads_actv_mean(\n","    means_dataset: Dataset,\n","    model: HookedTransformer\n",") -> Float[Tensor, \"layer batch seq head_idx d_head\"]:\n","    '''\n","    Output: The mean activations of a head's output\n","    '''\n","    _, means_cache = model.run_with_cache(\n","        means_dataset.toks.long(),\n","        return_type=None,\n","        names_filter=lambda name: name.endswith(\"z\"),\n","    )\n","    n_layers, n_heads, d_head = model.cfg.n_layers, model.cfg.n_heads, model.cfg.d_head\n","    batch, seq_len = len(means_dataset), means_dataset.max_len\n","    means = t.zeros(size=(n_layers, batch, seq_len, n_heads, d_head), device=model.cfg.device)\n","\n","    # for layer in range(model.cfg.n_layers):\n","    #     z_for_this_layer: Float[Tensor, \"batch seq head d_head\"] = means_cache[utils.get_act_name(\"z\", layer)]\n","    #     for template_group in means_dataset.groups:\n","    #         z_for_this_template = z_for_this_layer[template_group]\n","    #         z_means_for_this_template = einops.reduce(z_for_this_template, \"batch seq head d_head -> seq head d_head\", \"mean\")\n","    #         if z_means_for_this_template.shape[0] == 5:\n","    #             pdb.set_trace()\n","    #         means[layer, template_group] = z_means_for_this_template\n","\n","    del(means_cache)\n","\n","    return means"],"metadata":{"id":"6KlWYoEy72Cf","executionInfo":{"status":"ok","timestamp":1728033024057,"user_tz":240,"elapsed":330,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# def mask_circ_heads(\n","#     means_dataset: Dataset,\n","#     model: HookedTransformer,\n","#     circuit: Dict[str, List[Tuple[int, int]]],\n","#     seq_pos_to_keep: Dict[str, str],\n","# ) -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","#     '''\n","#     Output: for each layer, a mask of circuit components that should not be ablated\n","#     '''\n","#     heads_and_posns_to_keep = {}\n","#     batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","\n","#     for layer in range(model.cfg.n_layers):\n","\n","#         mask = t.zeros(size=(batch, seq, n_heads))\n","\n","#         for (head_type, head_list) in circuit.items():\n","#             seq_pos = seq_pos_to_keep[head_type]\n","#             # if seq_pos == 'S7':\n","#             #     pdb.set_trace()\n","#             indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","#             for (layer_idx, head_idx) in head_list:\n","#                 if layer_idx == layer:\n","#                     # if indices.item() == 7:\n","#                     #     pdb.set_trace()\n","#                     mask[:, indices, head_idx] = 1\n","#                     # mask[:, :, head_idx] = 1  # keep L.H at all pos\n","\n","#         heads_and_posns_to_keep[layer] = mask.bool()\n","#     # pdb.set_trace()\n","#     return heads_and_posns_to_keep"],"metadata":{"id":"bFDQMOt9CyVw","executionInfo":{"status":"ok","timestamp":1728033024907,"user_tz":240,"elapsed":5,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def mask_circ_heads(\n","    means_dataset: Dataset,\n","    model: HookedTransformer,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n",") -> Dict[int, Bool[Tensor, \"batch seq head\"]]:\n","    '''\n","    Output: for each layer, a mask of circuit components that should not be ablated\n","    '''\n","    heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = len(means_dataset), means_dataset.max_len, model.cfg.n_heads\n","    batch, seq, n_heads = len(means_dataset), len(circuit.keys()), model.cfg.n_heads\n","    # print(seq)\n","\n","    for layer in range(model.cfg.n_layers):\n","\n","        mask = t.zeros(size=(batch, seq, n_heads))\n","\n","        for (head_type, head_list) in circuit.items():\n","            seq_pos = seq_pos_to_keep[head_type]\n","            indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","            for (layer_idx, head_idx) in head_list:\n","                if layer_idx == layer:\n","                    # mask[:, indices, head_idx] = 1\n","                    mask[:, :, head_idx] = 1\n","\n","        heads_and_posns_to_keep[layer] = mask.bool()\n","\n","    return heads_and_posns_to_keep"],"metadata":{"id":"E1boH1469_HI","executionInfo":{"status":"ok","timestamp":1728033024907,"user_tz":240,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def hook_func_mask_head(\n","    z: Float[Tensor, \"batch seq head d_head\"],\n","    hook: HookPoint,\n","    # components_to_keep: Dict[int, Bool[Tensor, \"batch seq head\"]],\n","    # means: Float[Tensor, \"layer batch seq head d_head\"],\n","    circuit: Dict[str, List[Tuple[int, int]]],\n",") -> Float[Tensor, \"batch seq head d_head\"]:\n","    '''\n","    Use this to not mask components\n","    '''\n","    # mask_for_this_layer = components_to_keep[hook.layer()].unsqueeze(-1).to(z.device)\n","    # z = t.where(mask_for_this_layer, z, means[hook.layer()])\n","\n","    ###\n","    # heads_and_posns_to_keep = {}\n","    # batch, seq, n_heads = z.shape[0], z.shape[1], model.cfg.n_heads  # components_to_keep[0].shape[0] is batch\n","\n","    # for layer in range(model.cfg.n_layers):\n","\n","    #     mask = t.zeros(size=(batch, seq, n_heads))\n","\n","    #     for (head_type, head_list) in circuit.items():\n","    #         # seq_pos = seq_pos_to_keep[head_type]\n","    #         # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","    #         for (layer_idx, head_idx) in head_list:\n","    #             if layer_idx == layer:\n","    #                 # mask[:, indices, head_idx] = 1\n","    #                 mask[:, :, head_idx] = 1\n","\n","    #     heads_and_posns_to_keep[layer] = mask.bool()\n","    ###\n","    mask_for_this_layer = t.zeros(size=(z.shape[0], z.shape[1], z.shape[2]))\n","    for (head_type, head_list) in circuit.items():\n","        # seq_pos = seq_pos_to_keep[head_type]\n","        # indices = means_dataset.word_idx[seq_pos] # modify this for key vs query pos. curr, this is query\n","        for (layer_idx, head_idx) in head_list:\n","            if layer_idx == hook.layer():\n","                # mask[:, indices, head_idx] = 1\n","                mask_for_this_layer[:, :, head_idx] = 1\n","\n","    mask_for_this_layer = mask_for_this_layer.bool()\n","    mask_for_this_layer = mask_for_this_layer.unsqueeze(-1).to(z.device)  # d_model is 1; then is broadcast in where\n","\n","    z = t.where(mask_for_this_layer, z, 0)\n","\n","    return z"],"metadata":{"id":"KdxeNJ5C9tHx","executionInfo":{"status":"ok","timestamp":1728033024907,"user_tz":240,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def add_ablation_hook_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    circuit: Dict[str, List[Tuple[int, int]]],\n","    seq_pos_to_keep: Dict[str, str],\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    '''\n","    Ablate the model, except as components and positions to keep\n","    '''\n","\n","    model.reset_hooks(including_permanent=True)\n","    means = get_heads_actv_mean(means_dataset, model)\n","    components_to_keep = mask_circ_heads(means_dataset, model, circuit, seq_pos_to_keep)\n","\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=circuit,\n","    )\n","\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","    return model"],"metadata":{"id":"dg3XuWScAVvG","executionInfo":{"status":"ok","timestamp":1728033024907,"user_tz":240,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# from dataset import Dataset\n","from transformer_lens import HookedTransformer, utils\n","from transformer_lens.hook_points import HookPoint\n","import einops\n","from functools import partial\n","import torch as t\n","from torch import Tensor\n","from typing import Dict, Tuple, List\n","from jaxtyping import Float, Bool\n","\n","# from head_ablation_fns import *\n","# from mlp_ablation_fns import *\n","\n","def add_ablation_hook_MLP_head(\n","    model: HookedTransformer,\n","    means_dataset: Dataset,\n","    heads_lst, mlp_lst,\n","    is_permanent: bool = True,\n",") -> HookedTransformer:\n","    CIRCUIT = {}\n","    SEQ_POS_TO_KEEP = {}\n","    # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        CIRCUIT['S'+str(i)] = heads_lst\n","        # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","        # if i == num_pos - 1:\n","        #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","        # else:\n","        SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    model.reset_hooks(including_permanent=True)\n","\n","    # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    means = get_heads_actv_mean(means_dataset, model)\n","    # Convert this into a boolean map\n","    components_to_keep = mask_circ_heads(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # Get a hook function which will patch in the mean z values for each head, at\n","    # all positions which aren't important for the circuit\n","    hook_fn = partial(\n","        hook_func_mask_head,\n","        # components_to_keep=components_to_keep,\n","        # means=means,\n","        circuit=CIRCUIT,\n","    )\n","\n","    # Apply hook\n","    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=is_permanent)\n","\n","    # if all_entries_true(components_to_keep) == False:\n","    #     pdb.set_trace()\n","    ########################\n","    # CIRCUIT = {}\n","    # SEQ_POS_TO_KEEP = {}\n","    # # for i in range(len(model.tokenizer.tokenize(means_dataset.prompts[0]['text']))):\n","    # num_pos = len(model.tokenizer(means_dataset.prompts[0]['text']).input_ids)\n","    # for i in range(num_pos ):\n","    #     CIRCUIT['S'+str(i)] = mlp_lst\n","    #     # if i == len(model.tokenizer.tokenize(means_dataset.prompts[0]['text'])) - 1:\n","    #     # if i == num_pos - 1:\n","    #     #     SEQ_POS_TO_KEEP['S'+str(i)] = 'end'\n","    #     # else:\n","    #     SEQ_POS_TO_KEEP['S'+str(i)] = 'S'+str(i)\n","\n","    # # Compute the mean of each head's output on the ABC dataset, grouped by template\n","    # means = get_MLPs_actv_mean(means_dataset, model)\n","\n","    # # Convert this into a boolean map\n","    # components_to_keep = mask_circ_MLPs(means_dataset, model, CIRCUIT, SEQ_POS_TO_KEEP)\n","\n","    # # Get a hook function which will patch in the mean z values for each head, at\n","    # # all positions which aren't important for the circuit\n","    # hook_fn = partial(\n","    #     hook_func_mask_mlp_out,\n","    #     components_to_keep=components_to_keep,\n","    #     means=means\n","    # )\n","\n","    # model.add_hook(lambda name: name.endswith(\"mlp_out\"), hook_fn, is_permanent=True)\n","\n","    return model"],"metadata":{"id":"6ILjxwH9YUYP","executionInfo":{"status":"ok","timestamp":1728033024907,"user_tz":240,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def all_entries_true(tensor_dict):\n","    for key, tensor in tensor_dict.items():\n","        if not torch.all(tensor).item():\n","            return False\n","    return True"],"metadata":{"id":"u-YuOEDieLgE","executionInfo":{"status":"ok","timestamp":1728033024907,"user_tz":240,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["# ablation fns mult tok answers"],"metadata":{"id":"ZNunewNEy1po"}},{"cell_type":"code","source":["def clean_gen(model, clean_text, corr_ans):\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    tokens = model.to_tokens(clean_text).to(device)\n","    # tokens = tokens[:, 1:] # get rid of prepend bos when using model.to_tokens\n","\n","    total_score = 0\n","    corr_ans_tokLen = 0\n","    ans_so_far = ''\n","    # while True:\n","    for i in range(5):\n","        print(f\"Sequence so far: {model.to_string(tokens)[0]!r}\")\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        corr_logits = logits[:, -1, next_token]\n","        total_score += corr_logits\n","        print(f\"logit diff of new char: {corr_logits}\")\n","\n","        ans_so_far += next_char\n","        corr_ans_tokLen += 1\n","        print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","        if ans_so_far == corr_ans:\n","            print('\\nTotal logit diff: ', total_score.item())\n","            break\n","\n","        # Define new input sequence, by appending the previously generated token\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","        # if next_char == '':\n","        #     next_char = ' '\n","        # clean_text = clean_text + next_char\n","        # tokens = model.to_tokens(clean_text).to(device)\n","    return corr_ans_tokLen"],"metadata":{"id":"nesW2sVYy1po","executionInfo":{"status":"ok","timestamp":1728033025980,"user_tz":240,"elapsed":4,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    logits = model(tokens)\n","    next_token = logits[0, -1].argmax(dim=-1)\n","    next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","\n","    for i in range(corr_ans_tokLen):\n","        if next_char == '':\n","            next_char = ' '\n","\n","        clean_text = clean_text + next_char\n","        # if i == corr_ans_tokLen - 1:\n","        #     print(model.to_string(tokens))\n","            # print(f\"Sequence so far: {clean_text}\")\n","            # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","\n","        # get new ablation dataset\n","        # model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        # corr_text = corr_text + next_char\n","        # corr_tokens = torch.cat([corr_tokens, next_token[None, None]], dim=-1)\n","        # prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","        # pos_dict = {}\n","        # num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","        # for i in range(num_pos ):\n","        #     pos_dict['S'+str(i)] = i\n","\n","        # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, corr_tokens)\n","\n","        # model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","        # total_score += new_score\n","        # print(f\"corr logit of new char: {new_score}\")\n","    # print('\\n Total corr logit: ', total_score.item())\n","    return model.to_string(tokens)"],"metadata":{"id":"zfUaZ8vwy1po","executionInfo":{"status":"ok","timestamp":1728033025980,"user_tz":240,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def ablate_auto_score(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, correct_ans):\n","    tokens = model.to_tokens(clean_text).to(device)\n","    prompts_list = generate_prompts_list_longer(clean_text, tokens)\n","\n","    corr_tokens = model.to_tokens(corr_text).to(device)\n","    prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","    pos_dict = {}\n","    num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","    for i in range(num_pos ):\n","        pos_dict['S'+str(i)] = i\n","    dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer)\n","    model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","    # logits = model(tokens)\n","    # next_token = logits[0, -1].argmax(dim=-1)\n","    # next_char = model.to_string(next_token)\n","\n","    total_score = 0\n","    ans_so_far = ''\n","    ans_str_tok = tokenizer.tokenize(correct_ans)[1:] # correct_ans is str\n","    corr_tokenIDs = []\n","    for correct_ansPos in range(len(ans_str_tok)):\n","        tokID = model.tokenizer.encode(ans_str_tok[correct_ansPos])[2:][0] # 2: to skip padding <s> and ''\n","        corr_tokenIDs.append(tokID)\n","    correct_ans_tokLen = len(corr_tokenIDs)\n","    for ansPos in range(correct_ans_tokLen):\n","        # if next_char == '':\n","        #     next_char = ' '\n","\n","        # clean_text = clean_text + next_char\n","        # if i == correct_ans_tokLen - 1:\n","        #     print(model.to_string(tokens))\n","        #     # print(f\"Sequence so far: {clean_text}\")\n","        #     # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        # tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","\n","        # get new ablation dataset\n","        # model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n","\n","        # corr_text = corr_text + next_char\n","        # corr_tokens = torch.cat([corr_tokens, next_token[None, None]], dim=-1)\n","        # prompts_list_2 = generate_prompts_list_longer(corr_text, corr_tokens)\n","\n","        # pos_dict = {}\n","        # num_pos = len(model.tokenizer(prompts_list_2[0]['text']).input_ids)\n","        # for i in range(num_pos ):\n","        #     pos_dict['S'+str(i)] = i\n","\n","        # dataset_2 = Dataset(prompts_list_2, pos_dict, model.tokenizer, corr_tokens)\n","\n","        # model = add_ablation_hook_MLP_head(model, dataset_2, heads_not_ablate, mlps_not_ablate)\n","\n","        logits = model(tokens)\n","        next_token = logits[0, -1].argmax(dim=-1) # Get the predicted token at the end of our sequence\n","        next_char = model.to_string(next_token)\n","\n","        if next_char == '':\n","            next_char = ' '\n","\n","        clean_text = clean_text + next_char\n","        # if i == correct_ans_tokLen - 1:\n","            # print(model.to_string(tokens))\n","            # print(f\"Sequence so far: {clean_text}\")\n","            # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        tokens = torch.cat([tokens, next_token[None, None]], dim=-1)\n","\n","        ans_so_far += next_char\n","        correct_ans_tokLen += 1\n","        # print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n","\n","        ansTok_IDs = torch.tensor(corr_tokenIDs[ansPos])\n","\n","        # new_score = get_logit_diff(logits, dataset)\n","        # total_score += new_score\n","        # corrTok_logits = logits[:, -1, next_token]\n","        corrTok_logits = logits[range(logits.size(0)), -1, ansTok_IDs]  # not next_token, as that's what's pred, not the token to measure\n","        # pdb.set_trace()\n","        total_score += corrTok_logits\n","        # print(f\"corr logit of new char: {new_score}\")\n","    # print('\\n Total corr logit: ', total_score.item())\n","    # return ans_so_far, total_score.item()\n","    return ans_so_far"],"metadata":{"id":"-kvPgb12oYLi","executionInfo":{"status":"ok","timestamp":1728033025980,"user_tz":240,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qCVySrfhk-YH"},"source":["# auto measure fns"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"4Njf4fDdk_k9","executionInfo":{"status":"ok","timestamp":1728033026281,"user_tz":240,"elapsed":3,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def ablate_circ_autoScore(model, circuit, sequences_as_str, next_members):\n","    corr_text = \"5 3 9\"\n","    list_outputs = []\n","    score = 0\n","    for clean_text, correct_ans in zip(sequences_as_str, next_members):\n","        correct_ans_tokLen = clean_gen(model, clean_text, correct_ans)\n","\n","        heads_not_ablate = [(layer, head) for layer in range(32) for head in range(32)]  # unablated\n","        head_to_remove = circuit\n","        heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","        mlps_not_ablate = [layer for layer in range(32)]\n","\n","        output_after_ablate = ablate_auto_score(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, correct_ans_tokLen)\n","        list_outputs.append(output_after_ablate)\n","        print(correct_ans, output_after_ablate)\n","        if correct_ans == output_after_ablate:\n","            score += 1\n","    perc_score = score / len(next_members)\n","    return perc_score, list_outputs"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"CswxAMn4oRfW","executionInfo":{"status":"ok","timestamp":1728033026281,"user_tz":240,"elapsed":2,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def ablate_randcirc_autoScore(model, sequences_as_str, next_members, num_rand_runs, heads_not_overlap, num_heads_rand, num_not_overlap):\n","    corr_text = \"5 3 9\"\n","    list_outputs = []\n","    all_scores = []\n","    for clean_text, correct_ans in zip(sequences_as_str, next_members):\n","        prompt_score = 0\n","        correct_ans_tokLen = clean_gen(model, clean_text, correct_ans)\n","        for j in range(num_rand_runs):\n","            all_possible_pairs =  [(layer, head) for layer in range(32) for head in range(32)]\n","            filtered_pairs = [pair for pair in all_possible_pairs if pair not in heads_not_overlap] # Filter out heads_not_overlap from all_possible_pairs\n","\n","            # Randomly choose num_heads_rand pairs ensuring less than num_not_overlap overlaps with heads_not_overlap\n","            head_to_remove = choose_heads_to_remove(filtered_pairs, heads_not_overlap, num_heads_rand, num_not_overlap)\n","\n","            heads_not_ablate = [x for x in all_possible_pairs if x not in head_to_remove]\n","\n","            mlps_not_ablate = [layer for layer in range(32)]\n","\n","            output_after_ablate = ablate_auto_score(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, correct_ans_tokLen)\n","            # list_outputs.append(output_after_ablate)\n","            # print(correct_ans, output_after_ablate)\n","            if correct_ans == output_after_ablate:\n","                prompt_score += 1\n","        print(prompt_score / num_rand_runs)\n","        all_scores.append(prompt_score / num_rand_runs)\n","\n","    perc_score = sum(all_scores) / len(next_members)\n","    return perc_score, list_outputs"]},{"cell_type":"markdown","source":["# 1 2 3 genr ablation expms"],"metadata":{"id":"H5H-d2URUSVJ"}},{"cell_type":"code","source":["clean_text = \"1 2 3\"\n","corr_text = \"5 3 9\""],"metadata":{"id":"rseVgwqtjnCc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ablate just head 9.1 and MLP 9"],"metadata":{"id":"cvDoLG2YR73k"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFezBzOtje6o","executionInfo":{"status":"ok","timestamp":1716842180888,"user_tz":240,"elapsed":4265,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"42f28160-3428-4a32-db78-5ada39d48d6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 4'\n","1 2 3 4\n","5 3 9 4\n","\n","\n","Sequence so far: '1 2 3 4'\n","corr logit of new char: 0.42961740493774414\n","5th char = ' 5'\n","1 2 3 4 5\n","5 3 9 4 5\n","\n","\n","Sequence so far: '1 2 3 4 5'\n","corr logit of new char: 0.42962169647216797\n","6th char = ' 6'\n","1 2 3 4 5 6\n","5 3 9 4 5 6\n","\n","\n","Sequence so far: '1 2 3 4 5 6'\n","corr logit of new char: 0.4296226501464844\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","5 3 9 4 5 6 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 0.42961835861206055\n","8th char = ' 8'\n","1 2 3 4 5 6 7 8\n","5 3 9 4 5 6 7 8\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8'\n","corr logit of new char: 0.42961645126342773\n","\n"," Total corr logit:  2.1480965614318848\n"]}]},{"cell_type":"markdown","source":["## ablate 4.4, 7.11, 9.1"],"metadata":{"id":"NXLKleFoSQMO"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzSEb7OGj0vt","executionInfo":{"status":"ok","timestamp":1716842184417,"user_tz":240,"elapsed":3677,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bd99eca8-0f1b-48bf-a531-419cc4164ea2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 4'\n","1 2 3 4\n","5 3 9 4\n","\n","\n","Sequence so far: '1 2 3 4'\n","corr logit of new char: 3.36678409576416\n","5th char = ' 5'\n","1 2 3 4 5\n","5 3 9 4 5\n","\n","\n","Sequence so far: '1 2 3 4 5'\n","corr logit of new char: 3.3667917251586914\n","6th char = ' 6'\n","1 2 3 4 5 6\n","5 3 9 4 5 6\n","\n","\n","Sequence so far: '1 2 3 4 5 6'\n","corr logit of new char: 3.3667922019958496\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","5 3 9 4 5 6 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 3.3667869567871094\n","8th char = ' 8'\n","1 2 3 4 5 6 7 8\n","5 3 9 4 5 6 7 8\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8'\n","corr logit of new char: 3.3667917251586914\n","\n"," Total corr logit:  16.833946228027344\n"]}]},{"cell_type":"markdown","source":["## ablate mlp 9"],"metadata":{"id":"StWTdvI1hz4H"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgoE5T8DkCd_","executionInfo":{"status":"ok","timestamp":1716842188667,"user_tz":240,"elapsed":4426,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a603f0c1-156e-4adc-eab8-a46e9ba5da08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 4'\n","1 2 3 4\n","5 3 9 4\n","\n","\n","Sequence so far: '1 2 3 4'\n","corr logit of new char: 0.8109622001647949\n","5th char = ' 5'\n","1 2 3 4 5\n","5 3 9 4 5\n","\n","\n","Sequence so far: '1 2 3 4 5'\n","corr logit of new char: 0.8109650611877441\n","6th char = ' 6'\n","1 2 3 4 5 6\n","5 3 9 4 5 6\n","\n","\n","Sequence so far: '1 2 3 4 5 6'\n","corr logit of new char: 0.8109645843505859\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","5 3 9 4 5 6 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 0.8109612464904785\n","8th char = ' 8'\n","1 2 3 4 5 6 7 8\n","5 3 9 4 5 6 7 8\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8'\n","corr logit of new char: 0.8109622001647949\n","\n"," Total corr logit:  4.054815292358398\n"]}]},{"cell_type":"markdown","source":["## ablate 4.4, 7.11, 9.1 and mlp 9"],"metadata":{"id":"pJ804aWuhqu8"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7Y8FTbHkJjt","executionInfo":{"status":"ok","timestamp":1716842192393,"user_tz":240,"elapsed":3909,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"76b32457-a325-4ec1-963d-d86b016d58f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 3'\n","1 2 3 3\n","5 3 9 3\n","\n","\n","Sequence so far: '1 2 3 3'\n","corr logit of new char: -1.0452260971069336\n","5th char = ' 3'\n","1 2 3 3 3\n","5 3 9 3 3\n","\n","\n","Sequence so far: '1 2 3 3 3'\n","corr logit of new char: -1.0452265739440918\n","6th char = ' 3'\n","1 2 3 3 3 3\n","5 3 9 3 3 3\n","\n","\n","Sequence so far: '1 2 3 3 3 3'\n","corr logit of new char: -1.0452251434326172\n","7th char = ' 3'\n","1 2 3 3 3 3 3\n","5 3 9 3 3 3 3\n","\n","\n","Sequence so far: '1 2 3 3 3 3 3'\n","corr logit of new char: -1.0452260971069336\n","8th char = ' 3'\n","1 2 3 3 3 3 3 3\n","5 3 9 3 3 3 3 3\n","\n","\n","Sequence so far: '1 2 3 3 3 3 3 3'\n","corr logit of new char: -1.0452251434326172\n","\n"," Total corr logit:  -5.226129055023193\n"]}]},{"cell_type":"markdown","source":["## 6.2, 4.1, 7.1"],"metadata":{"id":"JSQkrPMHiJYI"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(6, 2), (4,1), (7,1)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npTQNLgIk5Pr","executionInfo":{"status":"ok","timestamp":1716842197848,"user_tz":240,"elapsed":5612,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"8b268740-7ffc-45d6-877b-1d42d81a8b0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: '1 2 3'\n","4th char = ' 4'\n","1 2 3 4\n","5 3 9 4\n","\n","\n","Sequence so far: '1 2 3 4'\n","corr logit of new char: 0.8091115951538086\n","5th char = ' 5'\n","1 2 3 4 5\n","5 3 9 4 5\n","\n","\n","Sequence so far: '1 2 3 4 5'\n","corr logit of new char: 0.8091144561767578\n","6th char = ' 6'\n","1 2 3 4 5 6\n","5 3 9 4 5 6\n","\n","\n","Sequence so far: '1 2 3 4 5 6'\n","corr logit of new char: 0.8091154098510742\n","7th char = ' 7'\n","1 2 3 4 5 6 7\n","5 3 9 4 5 6 7\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7'\n","corr logit of new char: 0.809107780456543\n","8th char = ' 8'\n","1 2 3 4 5 6 7 8\n","5 3 9 4 5 6 7 8\n","\n","\n","Sequence so far: '1 2 3 4 5 6 7 8'\n","corr logit of new char: 0.8091120719909668\n","\n"," Total corr logit:  4.04556131362915\n"]}]},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","# heads_not_ablate = [(9, 1)]\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","len(heads_not_ablate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhE8CDftXmMj","executionInfo":{"status":"ok","timestamp":1716842197848,"user_tz":240,"elapsed":232,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e841a833-2519-4c03-a220-2385b8441c0a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["141"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# one two three"],"metadata":{"id":"APiwKoUD9MM6"}},{"cell_type":"code","source":["clean_text = \"one two three\"\n","corr_text = \"five nine two\"\n","corr_ans_tokLen = 1"],"metadata":{"id":"24_968909MM7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"dGxJvhEJ9MM8"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842246062,"user_tz":240,"elapsed":1259,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"298baae1-4873-4d4c-a659-d1e7ec606ea4","id":"VxCow5xf9MM8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 5.505155086517334\n","\n"," Total corr logit:  5.505155086517334\n"]}]},{"cell_type":"markdown","source":["corrupt the subcircuit"],"metadata":{"id":"TT8O39J29MM9"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842247365,"user_tz":240,"elapsed":1455,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"24877a65-cb7e-4829-d8f7-33f9d23f2dd0","id":"z3GcWDTc9MM9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = '-'\n","one two three-\n","five nine two-\n","\n","\n","Sequence so far: 'one two three-'\n","corr logit of new char: -0.5595006942749023\n","\n"," Total corr logit:  -0.5595006942749023\n"]}]},{"cell_type":"markdown","source":["ablate 4.4, 7.11, 9.1"],"metadata":{"id":"sAzUkqoVGBn1"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842248609,"user_tz":240,"elapsed":1396,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f2e0eb14-41a1-4aeb-e382-620ca44beed1","id":"KrNA2cTQGBn4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = '-'\n","one two three-\n","five nine two-\n","\n","\n","Sequence so far: 'one two three-'\n","corr logit of new char: -1.0319595336914062\n","\n"," Total corr logit:  -1.0319595336914062\n"]}]},{"cell_type":"markdown","source":["corrupt 9.1 and mlp9"],"metadata":{"id":"NZQI29DW9MM-"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842249502,"user_tz":240,"elapsed":1052,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a749565a-79bf-40d9-c819-799109febb9e","id":"vnj-1qq79MM-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 2.635061264038086\n","\n"," Total corr logit:  2.635061264038086\n"]}]},{"cell_type":"markdown","source":["ablate mlp 9"],"metadata":{"id":"WX2JdPiN9MM-"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842250411,"user_tz":240,"elapsed":915,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"00beec79-a07f-4ca6-f235-7c90d9d6a47e","id":"gVHSuZuP9MM-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 3.019651412963867\n","\n"," Total corr logit:  3.019651412963867\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"oKOlOISe9MM_"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842251783,"user_tz":240,"elapsed":1378,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4b04554f-26cf-498a-9a9a-cf5afdee65bc","id":"chuCtE9w9MM_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 5.045960903167725\n","\n"," Total corr logit:  5.045960903167725\n"]}]},{"cell_type":"markdown","source":["ablate random head"],"metadata":{"id":"jKLK1cG-9MM_"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842252571,"user_tz":240,"elapsed":932,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"e5a0d47d-ae40-473a-e6bf-8734ea7a95b2","id":"A0TkDv0Z9MM_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' four'\n","one two three four\n","five nine two four\n","\n","\n","Sequence so far: 'one two three four'\n","corr logit of new char: 5.4420366287231445\n","\n"," Total corr logit:  5.4420366287231445\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"z1CwiVib9MM_"}},{"cell_type":"code","source":["heads_not_ablate = [ ]\n","\n","mlps_not_ablate = []\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842253337,"user_tz":240,"elapsed":780,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"4b26f03c-f392-4ab0-b984-092ddd4b4475","id":"IhDpClAM9MNA"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'one two three'\n","4th char = ' five'\n","one two three five\n","five nine two five\n","\n","\n","Sequence so far: 'one two three five'\n","corr logit of new char: -0.12970507144927979\n","\n"," Total corr logit:  -0.12970507144927979\n"]}]},{"cell_type":"markdown","source":["# January February March"],"metadata":{"id":"YNb5u__D-mho"}},{"cell_type":"code","source":["clean_text = \"January February March\"\n","corr_text = \"April July July\"\n","corr_ans_tokLen = 1"],"metadata":{"id":"NKMrT7AM-mhu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["clean"],"metadata":{"id":"Ntg-NYMI-mhw"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842254360,"user_tz":240,"elapsed":1034,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"a7bff45c-9962-4771-9b09-e7687f3e3ce8","id":"nqempkAq-mhx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: 9.440199851989746\n","\n"," Total corr logit:  9.440199851989746\n"]}]},{"cell_type":"markdown","source":["corrupt the subcircuit"],"metadata":{"id":"4bBGK0fT-mhz"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842255835,"user_tz":240,"elapsed":1489,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"f943f4c3-03b9-45f8-b4ef-f93fedbe3e8f","id":"sYwo-hbN-mhz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' August'\n","January February March August\n","April July July August\n","\n","\n","Sequence so far: 'January February March August'\n","corr logit of new char: -1.1505086421966553\n","\n"," Total corr logit:  -1.1505086421966553\n"]}]},{"cell_type":"markdown","source":["ablate 4.4, 7.11, 9.1"],"metadata":{"id":"IW9C9na0GlWw"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842256956,"user_tz":240,"elapsed":1259,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c7c72f13-a45a-4940-b37d-e639b92e7971","id":"LHkMwhk2GlWz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: 0.5852069854736328\n","\n"," Total corr logit:  0.5852069854736328\n"]}]},{"cell_type":"markdown","source":["corrupt 9.1 and mlp9"],"metadata":{"id":"glwEPyTQ-mh0"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842258007,"user_tz":240,"elapsed":1199,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"42f40d32-894a-433d-d973-04c5ec1ce2e1","id":"FmRYyq8i-mh2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: -3.3458361625671387\n","\n"," Total corr logit:  -3.3458361625671387\n"]}]},{"cell_type":"markdown","source":["ablate mlp 9"],"metadata":{"id":"0aqu4XD4-mh3"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842258568,"user_tz":240,"elapsed":580,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"c5e22a32-50e1-48dc-bbf4-4de0d2e9a73a","id":"6nVsvIfx-mh3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: -0.9824318885803223\n","\n"," Total corr logit:  -0.9824318885803223\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"r9hYFKPu-mh3"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((9, 1))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842259475,"user_tz":240,"elapsed":917,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"57ec3d61-b297-4c50-b63d-c0352b8b508c","id":"ft2EwL5Q-mh4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: 8.566516876220703\n","\n"," Total corr logit:  8.566516876220703\n"]}]},{"cell_type":"markdown","source":["ablate random head"],"metadata":{"id":"SBYrnRrf-mh6"}},{"cell_type":"code","source":["heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","heads_not_ablate.remove((6, 2))\n","\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842262736,"user_tz":240,"elapsed":3277,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b4007dd5-d30e-4ec7-9652-e1aece131c87","id":"zWIkcejk-mh6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' April'\n","January February March April\n","April July July April\n","\n","\n","Sequence so far: 'January February March April'\n","corr logit of new char: 9.635494232177734\n","\n"," Total corr logit:  9.635494232177734\n"]}]},{"cell_type":"markdown","source":["ablate all"],"metadata":{"id":"OSLJ4_sa-mh7"}},{"cell_type":"code","source":["heads_not_ablate = [ ]\n","\n","mlps_not_ablate = []\n","\n","ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, corr_ans_tokLen)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716842263671,"user_tz":240,"elapsed":944,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"33ed036f-e552-4fe1-ec57-0a112fb1ccdb","id":"eYGW8TdI-mh7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequence so far: 'January February March'\n","4th char = ' August'\n","January February March August\n","April July July August\n","\n","\n","Sequence so far: 'January February March August'\n","corr logit of new char: -1.855480670928955\n","\n"," Total corr logit:  -1.855480670928955\n"]}]},{"cell_type":"markdown","source":["# fns"],"metadata":{"id":"y12QUT2nyBBv"}},{"cell_type":"code","source":[],"metadata":{"id":"pup_jv65yCP7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# numerals"],"metadata":{"id":"P1S2f8MexvoX"}},{"cell_type":"code","source":["correct_prompts = []\n","for i in range(1, 9):\n","    correct_prompts.append(f\"{i} {i+1} {i+2} {i+3}\")"],"metadata":{"executionInfo":{"status":"ok","timestamp":1728033173308,"user_tz":240,"elapsed":306,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"id":"Hf3ocSJvyQ52"},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["corr_ans = []\n","for i in range(1, 9):\n","    corr_ans.append(str(i+4))"],"metadata":{"id":"wNj7U9H81sXO","executionInfo":{"status":"ok","timestamp":1728033784018,"user_tz":240,"elapsed":755,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# clean\n","num_corr = 0\n","corr_text = \"0 0 0 0\"\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","big3_outputs = []\n","lst_out = []\n","for clean_text, ans in zip(correct_prompts, corr_ans):\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 1)\n","    big3_outputs.append(prompt_out[0])\n","    answer = prompt_out[0].split(' ')[-1]\n","    lst_out.append(answer)\n","    if answer == ans:\n","        num_corr += 1\n","    # print(prompt_out[0])\n","print(lst_out)\n","print(num_corr / len(corr_ans))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1M26YGhvzey0","executionInfo":{"status":"ok","timestamp":1728033902669,"user_tz":240,"elapsed":1087,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"87995619-058f-485b-e1ab-06fecec69db6"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["['5', '6', '7', '8', '9', '10', '11', '12']\n","1.0\n"]}]},{"cell_type":"code","source":["# big 3 heads + MLP 9\n","heads_not_ablate = [(layer, head) for layer in range(12) for head in range(12)]  # unablated\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","corr_text = \"0 0 0 0\"\n","num_corr = 0\n","big3_outputs = []\n","lst_out = []\n","for clean_text, ans in zip(correct_prompts, corr_ans):\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 1)\n","    big3_outputs.append(prompt_out[0])\n","    answer = prompt_out[0].split(' ')[-1]\n","    lst_out.append(answer)\n","    if answer == ans:\n","        num_corr += 1\n","    print(prompt_out[0])\n","print(lst_out)\n","print(num_corr / len(corr_ans))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ork_azIk2N2T","executionInfo":{"status":"ok","timestamp":1728034087402,"user_tz":240,"elapsed":1613,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"14b7837e-510a-4622-b3a0-ccdcc794bf0f"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 12\n","['5', '6', '7', '8', '9', '10', '9', '12']\n","0.875\n"]}]},{"cell_type":"code","source":["# big 3 heads + MLP 9\n","corr_text = \"0 0 0 0\"\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","big3_outputs = []\n","for clean_text in correct_prompts:\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 1)\n","    big3_outputs.append(prompt_out[0])\n","    print(prompt_out[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1w7UzZqNx_1w","executionInfo":{"status":"ok","timestamp":1728034015825,"user_tz":240,"elapsed":1278,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b4d45016-4224-495c-8062-f1f9141725dd"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 12\n"]}]},{"cell_type":"code","source":["# ablate 4.4, 7.11, 9.1\n","corr_text = \"0 0 0 0\"\n","head_to_remove = ([(9, 1), (4,4), (7,11)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","mlps_not_ablate = [layer for layer in range(12)]\n","\n","big3_outputs = []\n","for clean_text in correct_prompts:\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 1)\n","    big3_outputs.append(prompt_out[0])\n","    print(prompt_out[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728033405741,"user_tz":240,"elapsed":1110,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"44aa2dac-da49-4830-eb10-62a243e4d2a9","id":"_-6BTwSRxvoY"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 12\n"]}]},{"cell_type":"code","source":["# corrupt 9.1 and mlp9\n","corr_text = \"0 0 0 0\"\n","head_to_remove = ([(9, 1)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","big3_outputs = []\n","for clean_text in correct_prompts:\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 1)\n","    big3_outputs.append(prompt_out[0])\n","    print(prompt_out[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728033477183,"user_tz":240,"elapsed":1380,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"80729a35-e995-4ae6-8bcc-9cf46984045e","id":"WChr_uyZxvoZ"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 12\n"]}]},{"cell_type":"code","source":["# ablate mlp 9\n","corr_text = \"0 0 0 0\"\n","head_to_remove = ([])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","big3_outputs = []\n","for clean_text in correct_prompts:\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 1)\n","    big3_outputs.append(prompt_out[0])\n","    print(prompt_out[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728033509120,"user_tz":240,"elapsed":1222,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"cce7bb4b-726a-4244-c67c-b4e82b104b15","id":"GnG1u097xvoZ"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 12\n"]}]},{"cell_type":"markdown","source":["ablate just 9.1"],"metadata":{"id":"d9C4RQnCxvoZ"}},{"cell_type":"code","source":["# ablate just 9.1\n","corr_text = \"0 0 0 0\"\n","head_to_remove = ([(9, 1)])\n","heads_not_ablate = [x for x in heads_not_ablate if (x not in head_to_remove)]\n","mlps_not_ablate = [layer for layer in range(12) ]\n","\n","big3_outputs = []\n","for clean_text in correct_prompts:\n","    prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate, mlps_not_ablate, 1)\n","    big3_outputs.append(prompt_out[0])\n","    print(prompt_out[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728033536125,"user_tz":240,"elapsed":1356,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"bf8d944e-44cf-4e3c-cbc0-aecca406b976","id":"TX13JspfxvoZ"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 12\n"]}]},{"cell_type":"code","source":["import random\n","\n","corr_text = \"0 0 0 0\"\n","mlps_not_ablate = [layer for layer in range(12) if layer != 9]\n","\n","# Define the number of runs\n","num_runs = 10\n","# Store outputs for each run\n","big3_outputs = []\n","\n","# Perform 10 runs, each time randomly selecting 3 heads to ablate\n","for _ in range(num_runs):\n","    # Randomly select 3 heads to ablate from heads_not_ablate\n","    heads_to_remove = random.sample(heads_not_ablate, 3)\n","    heads_not_ablate_run = [x for x in heads_not_ablate if (x not in heads_to_remove)]\n","\n","    for clean_text in correct_prompts:\n","        # Generate outputs with the randomly selected heads removed\n","        prompt_out = ablate_then_gen(model, clean_text, corr_text, heads_not_ablate_run, mlps_not_ablate, 1)\n","        big3_outputs.append(prompt_out[0])\n","        print(prompt_out[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mMiPAtRZ1P0o","executionInfo":{"status":"ok","timestamp":1728033664354,"user_tz":240,"elapsed":8830,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"78648d41-ee43-4f25-9605-49970c991c3c"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 9\n","<|endoftext|>7 8 9 10\n","\n","<|endoftext|>8 9 10 11\n","\n","<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 10\n","<|endoftext|>8 9 10 11 10\n","<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10\n","\n","<|endoftext|>8 9 10 11 12\n","<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 12\n","<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 7\n","<|endoftext|>6 7 8 9 8\n","<|endoftext|>7 8 9 10\n","\n","<|endoftext|>8 9 10 11\n","\n","<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 12\n","<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 7\n","<|endoftext|>6 7 8 9 9\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 10\n","<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 8\n","<|endoftext|>7 8 9 10 10\n","<|endoftext|>8 9 10 11 10\n","<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5\n","\n","<|endoftext|>3 4 5 6\n","\n","<|endoftext|>4 5 6 7\n","\n","<|endoftext|>5 6 7 8\n","\n","<|endoftext|>6 7 8 9\n","\n","<|endoftext|>7 8 9 10\n","\n","<|endoftext|>8 9 10 11\n","\n","<|endoftext|>1 2 3 4 5\n","<|endoftext|>2 3 4 5 6\n","<|endoftext|>3 4 5 6 7\n","<|endoftext|>4 5 6 7 8\n","<|endoftext|>5 6 7 8 9\n","<|endoftext|>6 7 8 9 10\n","<|endoftext|>7 8 9 10 9\n","<|endoftext|>8 9 10 11 12\n"]}]}]}