{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["u59fqaWVWMi3"],"authorship_tag":"ABX9TyPJ1/AzR3NyYy7wpmWJCn/Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"u59fqaWVWMi3"}},{"cell_type":"code","source":["!git clone https://github.com/jmerullo/lm_vector_arithmetic.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ktp63RzmJUmk","executionInfo":{"status":"ok","timestamp":1697066419587,"user_tz":240,"elapsed":761,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"764e37d1-48d8-42e6-e79b-e5b01f88c7d2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'lm_vector_arithmetic'...\n","remote: Enumerating objects: 35, done.\u001b[K\n","remote: Counting objects: 100% (35/35), done.\u001b[K\n","remote: Compressing objects: 100% (30/30), done.\u001b[K\n","remote: Total 35 (delta 10), reused 21 (delta 4), pack-reused 0\u001b[K\n","Receiving objects: 100% (35/35), 236.07 KiB | 3.93 MiB/s, done.\n","Resolving deltas: 100% (10/10), done.\n"]}]},{"cell_type":"code","source":["cd lm_vector_arithmetic"],"metadata":{"id":"yK8rs7ut_cqr","executionInfo":{"status":"ok","timestamp":1697066420949,"user_tz":240,"elapsed":172,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c98e6c54-2538-48b6-b328-5ddb2ef601de"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/lm_vector_arithmetic\n"]}]},{"cell_type":"code","source":["%%capture\n","!pip install -r requirements.txt"],"metadata":{"id":"PMa0Ry1uJ0N1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install transformers\n","\n","# import torch\n","# import transformers\n","# from transformers import AutoTokenizer, AutoModelForCausalLM\n","# import matplotlib.pyplot as plt\n","\n","# def load_gpt2(version):\n","#     device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","#     tokenizer = AutoTokenizer.from_pretrained(version)\n","#     model = AutoModelForCausalLM.from_pretrained(version, torch_dtype=torch.float16).to(device)\n","#     return model, tokenizer"],"metadata":{"id":"5oeopjKjBQ3M","executionInfo":{"status":"ok","timestamp":1697066260720,"user_tz":240,"elapsed":1482,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"24371864","executionInfo":{"status":"ok","timestamp":1697066423396,"user_tz":240,"elapsed":205,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["from modeling import *  #GPT2Wrapper, ModelWrapper"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"06f08857","executionInfo":{"status":"ok","timestamp":1697066454515,"user_tz":240,"elapsed":17194,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["model, tokenizer = load_gpt2('gpt2')\n","model = model.float()\n","wrapper = GPT2Wrapper(model, tokenizer)"]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"QZSSALUFF4EY"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"826df870","executionInfo":{"status":"ok","timestamp":1697066461767,"user_tz":240,"elapsed":266,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["def tokenize(text):\n","    inp_ids = wrapper.tokenize(text)\n","    str_toks = wrapper.list_decode(inp_ids[0])\n","    return inp_ids, str_toks\n","\n","def get_tokIDS(test_text):\n","    test_ids, test_toks = tokenize(test_text)\n","    logits = wrapper.get_layers(test_ids)\n","    wrapper.print_top(logits[1:]) #skip the first embedding layer b/c it just reverses to input\n","    return test_ids"]},{"cell_type":"code","source":["def create_layer_list(X, Y):\n","    layer_list = []\n","    for layer in range(X, Y+1):\n","        layer_list.append(\"Layer {}\".format(layer))\n","    return layer_list\n","\n","from tabulate import tabulate\n","def create_table(list1, list2):\n","    table_data = zip(list1, list2)\n","    headers = [\"Layer\", \"Orig Top Token\"]\n","    table = tabulate(table_data, headers, tablefmt=\"grid\")\n","    return table\n","\n","import torch.nn.functional as F\n","def get_decoded(logits, k=10):\n","    output_list = []\n","    for i,layer in enumerate(logits):\n","        output_list.append( wrapper.tokenizer.decode(F.softmax(layer,dim=-1).argsort(descending=True)[:k]) )\n","    return output_list\n","\n","def format_to_table(tok_ids):\n","    out = wrapper.model(input_ids = tok_ids, output_hidden_states=True)\n","    logits = out.logits\n","    hidden_states = out.hidden_states\n","    hidden_states = list(hidden_states)[1:]\n","\n","    orig_layer_logits = wrapper.layer_decode(hidden_states)\n","    orig_layer_logits = torch.stack(orig_layer_logits).squeeze(-1)\n","\n","    orig_decoded = get_decoded(orig_layer_logits)\n","    table_output = create_table(create_layer_list(0, 23), orig_decoded)\n","    print(table_output)"],"metadata":{"id":"VBKniAWQejlH","executionInfo":{"status":"ok","timestamp":1697066463309,"user_tz":240,"elapsed":431,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Test Template"],"metadata":{"id":"nKl9H9E625Vm"}},{"cell_type":"code","source":["test_text = \"\"\"1 2 3 4\"\"\"\n","test_ids = get_tokIDS(test_text)"],"metadata":{"id":"FWT7HZiyISOI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697066466185,"user_tz":240,"elapsed":1182,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"419faa24-5fd4-4a02-a684-2de6e0debdee"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["0 thteenthx 4 3teen3454 239\n","1 thteenth54x3934teen384174\n","2 thx3454GHz388639teen74\n","3 3454thGHz86ts743979x\n","4 tsms34thths54 -iel86 4\n","5 ts 4 - 3 5ths 6 +ms34\n","6  4★ 3 5 6 2 Tycoon >>> +ts\n","7  4 5 6 3 0 2 Tycoon 1ths 8\n","8  4 5 3 6 1 2 8 7★ 9\n","9  5 4 6 3 75 1 9 0★\n","10  5 6 4 3 7 1 05 9/\n","11  5 4 1 6 3 0/ 7\n","5\n"]}]},{"cell_type":"code","source":["format_to_table(test_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697066469374,"user_tz":240,"elapsed":719,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"b24b7be8-9520-4503-99d0-1b6a901e555c","id":"gD_OKQjmISOJ"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+---------------------------+\n","| Layer    | Orig Top Token            |\n","+==========+===========================+\n","| Layer 0  | thteenthx 4 3teen3454 239 |\n","+----------+---------------------------+\n","| Layer 1  | thteenth54x3934teen384174 |\n","+----------+---------------------------+\n","| Layer 2  | thx3454GHz388639teen74    |\n","+----------+---------------------------+\n","| Layer 3  | 3454thGHz86ts743979x      |\n","+----------+---------------------------+\n","| Layer 4  | tsms34thths54 -iel86 4    |\n","+----------+---------------------------+\n","| Layer 5  | ts 4 - 3 5ths 6 +ms34     |\n","+----------+---------------------------+\n","| Layer 6  | 4★ 3 5 6 2 Tycoon >>> +ts |\n","+----------+---------------------------+\n","| Layer 7  | 4 5 6 3 0 2 Tycoon 1ths 8 |\n","+----------+---------------------------+\n","| Layer 8  | 4 5 3 6 1 2 8 7★ 9        |\n","+----------+---------------------------+\n","| Layer 9  | 5 4 6 3 75 1 9 0★         |\n","+----------+---------------------------+\n","| Layer 10 | 5 6 4 3 7 1 05 9/         |\n","+----------+---------------------------+\n","| Layer 11 | 5 4 1 6 3 0/ 7            |\n","|          | 5                         |\n","+----------+---------------------------+\n"]}]},{"cell_type":"markdown","source":["# Test Template"],"metadata":{"id":"3RgDWf4gDDHc"}},{"cell_type":"code","source":["test_text = \"\"\"January February March April\"\"\"\n","test_ids = get_tokIDS(test_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697066547529,"user_tz":240,"elapsed":714,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"5fbbe114-0b43-4346-a85e-87464e647944","id":"3aNDTSoQDDHc"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["0  2015 May 2014 April June Aug 2013 July 2017 2016\n","1  2015 2014 2017 2013 2016 29 2018 27 May 24\n","2  2015 2014 29 2017 28 27 30 2013 2018 2016\n","3  29 2015 27 28 30 24 2014 25 26 23\n","4  24 29 2014 2015 2018 2017 27 30 28 26\n","5  29 24 30 28 27 4 3 26 2014 6\n","6  29 24 30 2014 28 26 2018 31 27 2015\n","7  2014 29 April 24 2015 2018 2019 2013 4 28\n","8  April 2014 May March 2015 June September 2017 October Apr\n","9  May April June 2015 5 July 2005 September March November\n","10  May June July AprilMay November September 5 March October\n","11  May June July 5\n"," April - MarchMay November\n"]}]},{"cell_type":"code","source":["format_to_table(test_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697066549367,"user_tz":240,"elapsed":553,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"52a9241f-5479-43fb-f0fe-3754ab771057","id":"74PYPeOTDDHd"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-----------------------------------------------------------+\n","| Layer    | Orig Top Token                                            |\n","+==========+===========================================================+\n","| Layer 0  | 2015 May 2014 April June Aug 2013 July 2017 2016          |\n","+----------+-----------------------------------------------------------+\n","| Layer 1  | 2015 2014 2017 2013 2016 29 2018 27 May 24                |\n","+----------+-----------------------------------------------------------+\n","| Layer 2  | 2015 2014 29 2017 28 27 30 2013 2018 2016                 |\n","+----------+-----------------------------------------------------------+\n","| Layer 3  | 29 2015 27 28 30 24 2014 25 26 23                         |\n","+----------+-----------------------------------------------------------+\n","| Layer 4  | 24 29 2014 2015 2018 2017 27 30 28 26                     |\n","+----------+-----------------------------------------------------------+\n","| Layer 5  | 29 24 30 28 27 4 3 26 2014 6                              |\n","+----------+-----------------------------------------------------------+\n","| Layer 6  | 29 24 30 2014 28 26 2018 31 27 2015                       |\n","+----------+-----------------------------------------------------------+\n","| Layer 7  | 2014 29 April 24 2015 2018 2019 2013 4 28                 |\n","+----------+-----------------------------------------------------------+\n","| Layer 8  | April 2014 May March 2015 June September 2017 October Apr |\n","+----------+-----------------------------------------------------------+\n","| Layer 9  | May April June 2015 5 July 2005 September March November  |\n","+----------+-----------------------------------------------------------+\n","| Layer 10 | May June July AprilMay November September 5 March October |\n","+----------+-----------------------------------------------------------+\n","| Layer 11 | May June July 5                                           |\n","|          |  April - MarchMay November                                |\n","+----------+-----------------------------------------------------------+\n"]}]}]}